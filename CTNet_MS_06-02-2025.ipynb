{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/bci-gpt/blob/main/CTNet_MS_06-02-2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Link utili:\n",
        "\n",
        "https://bnci-horizon-2020.eu/database/data-sets\n",
        "\n",
        "https://lampx.tugraz.at/~bci/database/001-2014/description.pdf\n",
        "\n",
        "https://arxiv.org/pdf/1806.06823"
      ],
      "metadata": {
        "id": "25ZNubsGO9MD"
      },
      "id": "25ZNubsGO9MD"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/marco-siino/bci-gpt.git\n",
        "%cd bci-gpt"
      ],
      "metadata": {
        "id": "HWnR7fdCnIuC",
        "outputId": "de60dbc8-2350-4b33-92ad-94e6da5055d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HWnR7fdCnIuC",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bci-gpt'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 27 (delta 9), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (27/27), 63.21 KiB | 534.00 KiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/bci-gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a3c0af06",
      "metadata": {
        "id": "a3c0af06",
        "outputId": "38e00f7f-fbd7-4a56-ce71-d1988e9b58ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.12.14)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "CTNet: A Convolution-Transformer Network for EEG-Based Motor Imagery Classification\n",
        "\n",
        "author: zhaowei701@163.com\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install mne\n",
        "\n",
        "import os\n",
        "gpus = [0]\n",
        "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "from pandas import ExcelWriter\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "from torch.backends import cudnn\n",
        "from utils import calMetrics\n",
        "from utils import calculatePerClass\n",
        "from utils import numberClassChannel\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from einops import rearrange, reduce, repeat\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from utils import numberClassChannel\n",
        "from utils import load_data_evaluate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "from scipy.io import savemat\n",
        "import scipy.io as sio\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the Dataset (Signals Data)"
      ],
      "metadata": {
        "id": "UDMXIlX5IzZe"
      },
      "id": "UDMXIlX5IzZe"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O BCICIV_2a_gdf.zip https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n"
      ],
      "metadata": {
        "id": "ehCLsnvkp0sO",
        "outputId": "dd844da5-d16e-4e50-efa0-b94bfdff89b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ehCLsnvkp0sO",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-06 12:01:40--  https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n",
            "Resolving www.bbci.de (www.bbci.de)... 130.149.80.149\n",
            "Connecting to www.bbci.de (www.bbci.de)|130.149.80.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439968864 (420M) [application/zip]\n",
            "Saving to: ‘BCICIV_2a_gdf.zip’\n",
            "\n",
            "BCICIV_2a_gdf.zip   100%[===================>] 419.59M  12.3MB/s    in 37s     \n",
            "\n",
            "2025-02-06 12:02:18 (11.4 MB/s) - ‘BCICIV_2a_gdf.zip’ saved [439968864/439968864]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip BCICIV_2a_gdf.zip -d ./BCICIV_2a_gdf/\n"
      ],
      "metadata": {
        "id": "I7ATagN2qEen",
        "outputId": "56e2eb7a-6a78-4cd0-b298-724303e3d0a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I7ATagN2qEen",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  BCICIV_2a_gdf.zip\n",
            "replace ./BCICIV_2a_gdf/A01E.gdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ./BCICIV_2a_gdf/A01E.gdf  \n",
            "replace ./BCICIV_2a_gdf/A01T.gdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the Labels"
      ],
      "metadata": {
        "id": "zNNpM3WrI4cW"
      },
      "id": "zNNpM3WrI4cW"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/marco-siino/bcidatasetIV2a.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FkcIYdLI8YN",
        "outputId": "81f07524-0e89-4cdb-ad38-3b45ba33da12"
      },
      "id": "6FkcIYdLI8YN",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bcidatasetIV2a'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Total 55 (delta 0), reused 0 (delta 0), pack-reused 55 (from 1)\u001b[K\n",
            "Receiving objects: 100% (55/55), 566.96 MiB | 31.50 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "Updating files: 100% (27/27), done.\n",
            "/content/bci-gpt/bcidatasetIV2a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/bci-gpt/bcidatasetIV2a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-g95jwQJl3J",
        "outputId": "84b09843-48fe-4327-fddd-d3b836eebf8b"
      },
      "id": "a-g95jwQJl3J",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bci-gpt/bcidatasetIV2a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a directory named true_labels\n",
        "!mkdir true_labels"
      ],
      "metadata": {
        "id": "QzKEnaGSJXwj"
      },
      "id": "QzKEnaGSJXwj",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 10):  # Da A01 a A09\n",
        "    for suffix in ['T', 'E']:  # Per ogni suffisso 'T' e 'E'\n",
        "        data = np.load(f\"A{i:02d}{suffix}.npz\")\n",
        "\n",
        "        # Se 'data['etyp']' è un array 2D, convertilo in 1D\n",
        "        etyp_array = data['etyp'].ravel()  # O usa .flatten()\n",
        "\n",
        "        # Usa numpy.isin() per trovare i valori desiderati\n",
        "        etyp_filtered = etyp_array[(np.isin(etyp_array, [769, 770, 771, 772]))]\n",
        "\n",
        "        print(len(etyp_filtered))\n",
        "\n",
        "        # Filtra la lista dei valori 'etyp' che sono tra 769, 770, 771, 772\n",
        "        #etyp_filtered = data['etyp'][data['etyp'].isin([769, 770, 771, 772])]\n",
        "\n",
        "        # Crea un dizionario per salvare i dati\n",
        "        data_to_save = {'classlabel': etyp_filtered.reshape(-1, 1)}\n",
        "        #data_to_save = {'classlabel': etyp_filtered}\n",
        "\n",
        "        # Salva il dizionario in un file .mat\n",
        "\n",
        "        sio.savemat(f\"/content/bci-gpt/bcidatasetIV2a/true_labels/A{i:02d}{suffix}.mat\", data_to_save)\n",
        "\n",
        "        print(\"File .mat creato con successo!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnC8R2A-KC2m",
        "outputId": "bf519c57-aed3-47aa-9336-7b48e9684310"
      },
      "id": "rnC8R2A-KC2m",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n",
            "288\n",
            "File .mat creato con successo!\n",
            "0\n",
            "File .mat creato con successo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the preprocessed Dataset."
      ],
      "metadata": {
        "id": "k4GkhNa9JVHj"
      },
      "id": "k4GkhNa9JVHj"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Function: Read files and preprocess them\n",
        "# Steps:\n",
        "# 1. Import data from the gdf file provided before the competition,\n",
        "#    remove unwanted channels, and select required events.\n",
        "# 2. Select desired time segments for slicing; treat each segment (4s) as one sample.\n",
        "# 3. Import labels from the mat file provided after the competition,\n",
        "#    ensuring they correspond with epochs and their numbers match.\n",
        "# 4. Save the resulting data in a new mat file,\n",
        "#    preparing it for use in the subsequent main.py.\n",
        "\"\"\"\n",
        "\n",
        "def changeGdf2Mat(dir_path, mode=\"train\"):\n",
        "    '''\n",
        "    read data from GDF files and store as mat files\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dir_path : str\n",
        "        GDF file dir path.\n",
        "    mode : str, optional\n",
        "        change train dataset or eval dataset. The default is \"train\".\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    '''\n",
        "    mode_str = ''\n",
        "    if mode==\"train\":\n",
        "        mode_str = 'T'\n",
        "    else:\n",
        "        mode_str = 'E'\n",
        "    for nSub in range(1, 10):\n",
        "        # Load the gdf file\n",
        "        data_filename = dir_path+'/A0{}{}.gdf'.format(nSub, mode_str)\n",
        "        print(\"\\n\\n******\\n\\nInizio con: \", data_filename,\"\\n\")\n",
        "        raw = mne.io.read_raw_gdf(data_filename)\n",
        "\n",
        "        print(raw)\n",
        "\n",
        "        # Select the events of interest\n",
        "        events, event_dict = mne.events_from_annotations(raw)\n",
        "\n",
        "        print(events)\n",
        "\n",
        "        print(event_dict)\n",
        "        if mode==\"train\":\n",
        "            # train dataset are labeled\n",
        "            event_id = {'Left': event_dict['769'],\n",
        "                        'Right': event_dict['770'],\n",
        "                        'Foot': event_dict['771'],\n",
        "                        'Tongue': event_dict['772']}\n",
        "        else:\n",
        "            # evaluate dataset are labeled as 'Unknnow'\n",
        "            event_id = {'Unknown': event_dict['783']}\n",
        "\n",
        "        # Select the events corresponding to the four categories we are interested in.\n",
        "        # Here, events[:, 2] refers to the third column of the events array, which represents the event IDs.\n",
        "        selected_events = events[np.isin(events[:, 2], list(event_id.values()))]\n",
        "\n",
        "        print(len(selected_events))\n",
        "\n",
        "        # remove EOG channels\n",
        "        raw.info['bads'] += ['EOG-left', 'EOG-central', 'EOG-right']\n",
        "        picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude='bads')\n",
        "        # Epoch the data\n",
        "        # using 4s (1000 sample point ) segmentation\n",
        "        epochs = mne.Epochs(raw, selected_events, event_id, picks=picks,tmin=0, tmax=3.996, preload=True, baseline=None)\n",
        "\n",
        "        filtered_data = epochs.get_data()\n",
        "\n",
        "        print(\"\\n\\n\", filtered_data.shape)\n",
        "\n",
        "        print(\"\\n\\n\", filtered_data[0])\n",
        "        #label_filename = '/content/bci-gpt/bcidatasetIV2a/true_labels/'+'A0{}{}.mat'.format(nSub, mode_str)\n",
        "        label_filename = '/content/bci-gpt/bcidatasetIV2a/true_labels/'+'A0{}T.mat'.format(nSub)\n",
        "\n",
        "        #label_filename = \"/content/A01T.mat\"\n",
        "        mat = sio.loadmat(label_filename)  # load target mat file\n",
        "        labels = mat['classlabel']\n",
        "\n",
        "        # Save the data and labels to a .mat file\n",
        "        result_filename = '/content/bci-gpt/preprocessed_ds/A0{}{}.mat'.format(nSub, mode_str)\n",
        "        print(len(filtered_data))\n",
        "        print(len(labels))\n",
        "        savemat(result_filename, {'data': filtered_data, 'label': labels})\n",
        "\n",
        "dir_path = '/content/bci-gpt/BCICIV_2a_gdf'\n",
        "# prepare train dataset\n",
        "changeGdf2Mat(dir_path, 'train')\n",
        "# prepare test dataset\n",
        "changeGdf2Mat(dir_path, 'eval')"
      ],
      "metadata": {
        "id": "6-3UNFNqo_Co",
        "outputId": "34cd592a-d8eb-4e34-d4a3-a19b85513e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6-3UNFNqo_Co",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A01T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A01T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A01T.gdf, 25 x 672528 (2690.1 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 29683      0      5]\n",
            " ...\n",
            " [670550      0      6]\n",
            " [670550      0      1]\n",
            " [671050      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 3.90625000e-07  6.29882813e-06  5.07812500e-06 ... -4.88281250e-06\n",
            "  -6.39648437e-06 -2.34375000e-06]\n",
            " [-4.24804687e-06  0.00000000e+00 -2.78320312e-06 ...  5.37109375e-07\n",
            "  -4.15039062e-06 -2.39257812e-06]\n",
            " [-4.05273438e-06  2.14843750e-06 -2.44140625e-07 ... -5.17578125e-06\n",
            "  -7.22656250e-06 -4.68750000e-06]\n",
            " ...\n",
            " [-5.71289063e-06 -3.46679687e-06 -8.05664063e-06 ...  1.95312500e-07\n",
            "  -7.42187500e-06 -7.47070312e-06]\n",
            " [-5.56640625e-06 -4.29687500e-06 -1.01074219e-05 ...  1.70898437e-06\n",
            "  -5.95703125e-06 -5.61523437e-06]\n",
            " [-2.14843750e-06 -1.22070313e-06 -5.51757812e-06 ...  2.92968750e-06\n",
            "  -4.19921875e-06 -5.76171875e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A02T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A02T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A02T.gdf, 25 x 677169 (2708.7 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 31513      0      5]\n",
            " ...\n",
            " [673632      0      7]\n",
            " [675191      0      6]\n",
            " [675691      0      9]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 1.31835937e-05  1.78222656e-05 -4.24804687e-06 ...  5.90820312e-06\n",
            "  -5.85937500e-06 -1.02539062e-05]\n",
            " [ 1.18652344e-05  1.41113281e-05 -5.95703125e-06 ...  6.93359375e-06\n",
            "  -1.56250000e-06 -7.95898437e-06]\n",
            " [ 1.25488281e-05  1.62109375e-05 -6.44531250e-06 ...  7.61718750e-06\n",
            "  -4.34570312e-06 -8.00781250e-06]\n",
            " ...\n",
            " [ 1.41113281e-05  1.56738281e-05 -5.02929688e-06 ...  1.26953125e-06\n",
            "  -8.39843750e-06 -1.34765625e-05]\n",
            " [ 1.36718750e-05  1.44042969e-05 -5.71289063e-06 ...  1.07421875e-06\n",
            "  -8.00781250e-06 -1.28906250e-05]\n",
            " [ 1.57714844e-05  1.67480469e-05 -1.90429687e-06 ...  1.31835937e-06\n",
            "  -8.05664063e-06 -1.33300781e-05]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A03T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A03T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A03T.gdf, 25 x 660530 (2642.1 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 23720      0      5]\n",
            " ...\n",
            " [656993      0      7]\n",
            " [658552      0      6]\n",
            " [659052      0      9]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-6.98242188e-06 -9.52148437e-06 -1.70898437e-06 ...  6.10351562e-06\n",
            "   9.03320312e-06  8.64257813e-06]\n",
            " [-7.22656250e-06 -8.88671875e-06  4.39453125e-07 ...  8.39843750e-06\n",
            "   7.56835937e-06  9.76562500e-06]\n",
            " [-8.10546875e-06 -1.18652344e-05 -4.73632813e-06 ...  7.12890625e-06\n",
            "   7.22656250e-06  6.83593750e-06]\n",
            " ...\n",
            " [-7.42187500e-06 -1.26464844e-05 -6.54296875e-06 ...  4.88281250e-06\n",
            "   3.80859375e-06  2.78320312e-06]\n",
            " [-7.86132812e-06 -1.33300781e-05 -8.00781250e-06 ...  5.81054687e-06\n",
            "   4.24804687e-06  2.97851562e-06]\n",
            " [-9.37500000e-06 -1.43066406e-05 -8.10546875e-06 ...  5.66406250e-06\n",
            "   4.29687500e-06  3.85742187e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A04T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A04T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A04T.gdf, 25 x 600915 (2403.7 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      3]\n",
            " [     0      0      2]\n",
            " [ 19905      0      3]\n",
            " ...\n",
            " [597378      0      6]\n",
            " [598937      0      4]\n",
            " [599437      0      5]]\n",
            "{'1023': 1, '1072': 2, '32766': 3, '768': 4, '769': 5, '770': 6, '771': 7, '772': 8}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 3.56445313e-06  3.75976562e-06  6.05468750e-06 ... -8.10546875e-06\n",
            "  -8.30078125e-06 -1.08886719e-05]\n",
            " [ 8.30078125e-07  7.42187500e-06  6.59179687e-06 ... -1.90429687e-06\n",
            "  -5.95703125e-06 -2.78320312e-06]\n",
            " [ 0.00000000e+00  1.26953125e-06  3.41796875e-06 ... -5.71289063e-06\n",
            "  -6.93359375e-06 -9.47265625e-06]\n",
            " ...\n",
            " [ 9.76562500e-08  2.14843750e-06  4.63867187e-06 ... -4.15039062e-06\n",
            "  -4.98046875e-06 -9.22851563e-06]\n",
            " [ 7.32421875e-07  2.88085937e-06  3.22265625e-06 ... -4.19921875e-06\n",
            "  -4.29687500e-06 -7.47070312e-06]\n",
            " [ 2.83203125e-06  8.20312500e-06  9.22851563e-06 ... -1.36718750e-06\n",
            "   5.37109375e-07 -5.46875000e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A05T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A05T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A05T.gdf, 25 x 686120 (2744.5 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 30139      0      5]\n",
            " ...\n",
            " [682583      0      7]\n",
            " [684142      0      6]\n",
            " [684642      0      9]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 1.74316406e-05  6.78710937e-06  1.66015625e-05 ... -9.47265625e-06\n",
            "  -1.27441406e-05 -8.93554688e-06]\n",
            " [ 1.59179687e-05  8.15429687e-06  1.45019531e-05 ... -1.00585938e-05\n",
            "  -1.53808594e-05 -8.00781250e-06]\n",
            " [ 1.54296875e-05  5.51757812e-06  1.48437500e-05 ... -1.15234375e-05\n",
            "  -1.52832031e-05 -1.20117188e-05]\n",
            " ...\n",
            " [ 6.68945312e-06 -1.85546875e-06  6.10351562e-06 ... -1.93359375e-05\n",
            "  -2.31445312e-05 -1.72363281e-05]\n",
            " [ 5.81054687e-06 -1.80664062e-06  7.51953125e-06 ... -1.98242187e-05\n",
            "  -2.15332031e-05 -1.69433594e-05]\n",
            " [ 1.85546875e-06 -6.68945312e-06  1.61132812e-06 ... -2.19726562e-05\n",
            "  -2.44628906e-05 -2.07519531e-05]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A06T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A06T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A06T.gdf, 25 x 678980 (2715.9 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 29184      0      5]\n",
            " ...\n",
            " [677002      0      6]\n",
            " [677002      0      1]\n",
            " [677502      0      9]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-4.44335938e-06 -9.03320312e-06 -1.53320312e-05 ... -2.92968750e-06\n",
            "  -4.44335938e-06 -3.07617188e-06]\n",
            " [-8.05664063e-06 -9.86328125e-06 -1.36718750e-05 ... -1.95312500e-06\n",
            "  -3.32031250e-06  3.07617188e-06]\n",
            " [-5.81054687e-06 -1.04492187e-05 -1.60156250e-05 ...  4.98046875e-06\n",
            "   1.95312500e-06  4.73632813e-06]\n",
            " ...\n",
            " [ 5.71289063e-06  2.29492188e-06 -5.37109375e-07 ...  3.22265625e-06\n",
            "  -1.95312500e-07  1.66015625e-06]\n",
            " [ 7.51953125e-06  4.88281250e-06  2.44140625e-07 ...  2.63671875e-06\n",
            "  -7.32421875e-07  1.07421875e-06]\n",
            " [ 8.59375000e-06  4.49218750e-06  2.92968750e-06 ...  0.00000000e+00\n",
            "  -2.05078125e-06 -1.36718750e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A07T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A07T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A07T.gdf, 25 x 681071 (2724.3 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 27170      0      5]\n",
            " ...\n",
            " [677534      0      7]\n",
            " [679093      0      6]\n",
            " [679593      0      9]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 1.56250000e-06  9.76562500e-07  1.17675781e-05 ... -8.20312500e-06\n",
            "  -7.86132812e-06 -6.00585938e-06]\n",
            " [-2.92968750e-07  4.58984375e-06  1.32324219e-05 ... -6.39648437e-06\n",
            "  -4.19921875e-06 -3.12500000e-06]\n",
            " [ 4.39453125e-07  2.63671875e-06  1.35742187e-05 ... -8.10546875e-06\n",
            "  -6.44531250e-06 -4.00390625e-06]\n",
            " ...\n",
            " [ 4.29687500e-06  4.58984375e-06  1.37207031e-05 ... -4.10156250e-06\n",
            "  -3.27148437e-06 -3.36914062e-06]\n",
            " [ 6.25000000e-06  5.41992187e-06  1.39648438e-05 ... -4.63867187e-06\n",
            "  -3.32031250e-06 -2.39257812e-06]\n",
            " [ 2.34375000e-06  2.29492188e-06  1.28417969e-05 ... -3.71093750e-06\n",
            "  -2.14843750e-06 -2.73437500e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A08T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A08T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A08T.gdf, 25 x 675270 (2701.1 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 30571      0      5]\n",
            " ...\n",
            " [671733      0      7]\n",
            " [673292      0      6]\n",
            " [673792      0      9]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-2.22167969e-05 -2.19726562e-05 -2.72460937e-05 ... -1.23046875e-05\n",
            "  -2.88085937e-06 -5.46875000e-06]\n",
            " [-2.02636719e-05 -2.26562500e-05 -2.72460937e-05 ... -1.86523437e-05\n",
            "  -1.06933594e-05 -9.27734375e-06]\n",
            " [-2.54394531e-05 -2.54882812e-05 -2.90527344e-05 ... -1.22558594e-05\n",
            "  -3.46679687e-06 -4.15039062e-06]\n",
            " ...\n",
            " [-1.53808594e-05 -1.41113281e-05 -1.88964844e-05 ... -3.27148437e-06\n",
            "   2.09960938e-06  5.37109375e-07]\n",
            " [-1.38183594e-05 -1.24023437e-05 -1.78222656e-05 ... -4.68750000e-06\n",
            "   1.95312500e-07 -1.07421875e-06]\n",
            " [-1.04980469e-05 -8.59375000e-06 -1.43066406e-05 ...  4.49218750e-06\n",
            "   7.66601562e-06  3.51562500e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A09T.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A09T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A09T.gdf, 25 x 673328 (2693.3 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 30878      0      5]\n",
            " ...\n",
            " [669791      0      8]\n",
            " [671350      0      6]\n",
            " [671850      0      9]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '769': 7, '770': 8, '771': 9, '772': 10}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 6.15234375e-06  5.76171875e-06  1.36718750e-06 ...  2.44140625e-06\n",
            "  -1.41601562e-06 -1.02539062e-06]\n",
            " [ 5.90820312e-06  6.98242188e-06  3.66210937e-06 ...  2.92968750e-06\n",
            "  -6.34765625e-07  3.66210937e-06]\n",
            " [ 6.83593750e-06  5.46875000e-06  2.58789063e-06 ...  6.00585938e-06\n",
            "   2.09960938e-06  3.71093750e-06]\n",
            " ...\n",
            " [ 9.47265625e-06  8.34960938e-06  3.17382812e-06 ...  5.32226562e-06\n",
            "   6.34765625e-07  2.05078125e-06]\n",
            " [ 9.57031250e-06  9.66796875e-06  3.32031250e-06 ...  1.12792969e-05\n",
            "   4.49218750e-06  4.34570312e-06]\n",
            " [ 1.20605469e-05  1.18652344e-05  4.54101562e-06 ...  1.12792969e-05\n",
            "   6.54296875e-06  7.86132812e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A01E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A01E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A01E.gdf, 25 x 687000 (2748.0 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 34291      0      5]\n",
            " ...\n",
            " [683463      0      7]\n",
            " [685022      0      6]\n",
            " [685522      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-6.59179687e-06 -8.88671875e-06 -1.22070312e-05 ...  3.71093750e-06\n",
            "  -9.76562500e-08 -1.95312500e-06]\n",
            " [-4.39453125e-06 -7.66601562e-06 -1.04492187e-05 ...  3.85742187e-06\n",
            "   1.46484375e-06  6.83593750e-07]\n",
            " [-5.66406250e-06 -6.83593750e-06 -1.00585938e-05 ...  6.68945312e-06\n",
            "   3.12500000e-06  1.80664062e-06]\n",
            " ...\n",
            " [-1.24511719e-05 -9.57031250e-06 -1.12304687e-05 ...  1.75781250e-06\n",
            "  -1.95312500e-07  1.41601562e-06]\n",
            " [-1.21582031e-05 -9.37500000e-06 -1.19628906e-05 ...  1.22070313e-06\n",
            "  -3.90625000e-07  7.32421875e-07]\n",
            " [-1.10839844e-05 -5.81054687e-06 -1.08398437e-05 ... -4.88281250e-07\n",
            "  -4.88281250e-08  2.49023437e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A02E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A02E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A02E.gdf, 25 x 662666 (2650.7 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 22901      0      5]\n",
            " ...\n",
            " [659129      0      7]\n",
            " [660688      0      6]\n",
            " [661188      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 2.63183594e-05  5.56640625e-06  3.20800781e-05 ... -1.51855469e-05\n",
            "  -3.75976562e-06 -1.42578125e-05]\n",
            " [ 2.07519531e-05 -1.95312500e-07  2.33886719e-05 ... -1.69433594e-05\n",
            "  -6.83593750e-06 -1.76757812e-05]\n",
            " [ 2.35351562e-05  1.51367187e-06  2.71484375e-05 ... -1.36230469e-05\n",
            "  -2.00195312e-06 -1.28906250e-05]\n",
            " ...\n",
            " [ 1.34765625e-05 -1.22558594e-05  1.28906250e-05 ... -1.04980469e-05\n",
            "  -9.76562500e-07 -1.14746094e-05]\n",
            " [ 1.33789062e-05 -1.14746094e-05  1.45019531e-05 ... -1.20117188e-05\n",
            "  -3.66210937e-06 -1.20117188e-05]\n",
            " [ 1.25000000e-05 -1.31835937e-05  1.22070312e-05 ... -8.44726562e-06\n",
            "  -8.78906250e-07 -1.29882812e-05]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A03E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A03E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A03E.gdf, 25 x 648775 (2595.1 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 19884      0      5]\n",
            " ...\n",
            " [645238      0      7]\n",
            " [646797      0      6]\n",
            " [647297      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-1.45019531e-05 -1.92871094e-05 -1.57714844e-05 ...  9.42382812e-06\n",
            "   2.33398437e-05  5.41992187e-06]\n",
            " [-1.13281250e-05 -1.65527344e-05 -7.08007812e-06 ...  8.25195312e-06\n",
            "   2.98828125e-05  1.97265625e-05]\n",
            " [-1.52832031e-05 -2.05566406e-05 -1.49902344e-05 ...  1.05468750e-05\n",
            "   2.68554688e-05  1.17675781e-05]\n",
            " ...\n",
            " [-4.88281250e-07 -4.88281250e-06  3.90625000e-06 ...  7.27539063e-06\n",
            "   2.33398437e-05  7.51953125e-06]\n",
            " [-8.30078125e-07 -5.95703125e-06  2.09960938e-06 ...  6.83593750e-06\n",
            "   2.42675781e-05  9.17968750e-06]\n",
            " [ 1.41601562e-06 -3.90625000e-06  5.46875000e-06 ...  5.61523437e-06\n",
            "   2.11914063e-05  8.44726562e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A04E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A04E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A04E.gdf, 25 x 660047 (2640.2 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 24266      0      5]\n",
            " ...\n",
            " [656510      0      7]\n",
            " [658069      0      6]\n",
            " [658569      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-7.17773437e-06  1.01074219e-05  2.05078125e-06 ...  9.76562500e-07\n",
            "   1.03027344e-05  7.22656250e-06]\n",
            " [-3.71093750e-06  1.26464844e-05  6.20117187e-06 ... -4.63867187e-06\n",
            "   6.54296875e-06 -4.88281250e-07]\n",
            " [-4.19921875e-06  1.49414062e-05  7.03125000e-06 ...  2.92968750e-07\n",
            "   1.04492187e-05  6.44531250e-06]\n",
            " ...\n",
            " [-7.32421875e-07  2.00195312e-05  1.41113281e-05 ... -2.24609375e-06\n",
            "   7.32421875e-06  4.68750000e-06]\n",
            " [-5.37109375e-07  2.01660156e-05  1.56250000e-05 ... -8.20312500e-06\n",
            "   1.41601562e-06 -8.78906250e-07]\n",
            " [ 1.07421875e-06  2.48535156e-05  1.92382812e-05 ... -3.95507812e-06\n",
            "   2.63671875e-06  5.85937500e-07]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A05E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A05E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A05E.gdf, 25 x 679863 (2719.5 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 31589      0      5]\n",
            " ...\n",
            " [676326      0      7]\n",
            " [677885      0      6]\n",
            " [678385      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 2.92968750e-07 -6.15234375e-06 -6.34765625e-06 ...  1.19628906e-05\n",
            "   5.46875000e-06 -6.05468750e-06]\n",
            " [ 2.00195312e-06 -4.05273438e-06 -1.12304687e-06 ...  1.58691406e-05\n",
            "   1.14746094e-05 -4.88281250e-06]\n",
            " [ 4.88281250e-07 -2.88085937e-06 -2.58789063e-06 ...  1.62109375e-05\n",
            "   6.29882813e-06 -1.16210937e-05]\n",
            " ...\n",
            " [ 4.29687500e-06 -4.63867187e-06 -2.00195312e-06 ...  9.47265625e-06\n",
            "   8.49609375e-06 -3.90625000e-06]\n",
            " [ 7.12890625e-06 -3.56445313e-06 -4.00390625e-06 ...  5.41992187e-06\n",
            "   4.15039062e-06 -6.34765625e-06]\n",
            " [ 1.14746094e-05 -7.81250000e-07 -4.58984375e-06 ...  3.46679687e-06\n",
            "   3.66210937e-06 -3.66210937e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A06E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A06E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A06E.gdf, 25 x 666373 (2665.5 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 25614      0      5]\n",
            " ...\n",
            " [662836      0      7]\n",
            " [664395      0      6]\n",
            " [664895      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[ 3.05175781e-05  2.43652344e-05  2.20703125e-05 ... -1.36718750e-06\n",
            "  -3.22265625e-06  3.46679687e-06]\n",
            " [ 2.97363281e-05  2.31445312e-05  1.53808594e-05 ... -1.95312500e-07\n",
            "   6.05468750e-06  8.10546875e-06]\n",
            " [ 2.41699219e-05  1.74316406e-05  1.66992188e-05 ...  1.46484375e-07\n",
            "   4.88281250e-08  6.05468750e-06]\n",
            " ...\n",
            " [ 1.63574219e-05  1.24023437e-05  1.40625000e-05 ...  9.42382812e-06\n",
            "   1.02050781e-05  1.09863281e-05]\n",
            " [ 1.39648438e-05  1.13281250e-05  1.33300781e-05 ...  6.20117187e-06\n",
            "   8.54492187e-06  7.91015625e-06]\n",
            " [ 9.52148437e-06  5.56640625e-06  8.88671875e-06 ...  5.71289063e-06\n",
            "   8.39843750e-06  1.12792969e-05]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A07E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A07E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A07E.gdf, 25 x 673135 (2692.5 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 27161      0      5]\n",
            " ...\n",
            " [669598      0      7]\n",
            " [671157      0      6]\n",
            " [671657      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-4.88281250e-08  2.09960938e-06  1.66015625e-06 ...  4.10156250e-06\n",
            "   1.07421875e-06  3.71093750e-06]\n",
            " [ 2.44140625e-06  6.29882813e-06  7.91015625e-06 ... -3.51562500e-06\n",
            "   9.76562500e-08 -3.90625000e-07]\n",
            " [ 5.37109375e-07  2.92968750e-06  3.07617188e-06 ...  2.63671875e-06\n",
            "   2.92968750e-07  2.00195312e-06]\n",
            " ...\n",
            " [ 1.75781250e-06  2.92968750e-06  2.88085937e-06 ...  6.83593750e-07\n",
            "  -1.12304687e-06  8.30078125e-07]\n",
            " [-9.27734375e-07  3.90625000e-07  1.46484375e-07 ...  1.46484375e-06\n",
            "  -1.46484375e-07  1.56250000e-06]\n",
            " [-2.24609375e-06  1.41601562e-06  3.66210937e-06 ... -7.32421875e-07\n",
            "  -1.12304687e-06  2.09960938e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A08E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A08E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A08E.gdf, 25 x 687792 (2751.2 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 32790      0      5]\n",
            " ...\n",
            " [684255      0      7]\n",
            " [685814      0      6]\n",
            " [686314      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-5.51757812e-06  6.64062500e-06  2.33398437e-05 ...  1.01074219e-05\n",
            "   1.75781250e-06  6.83593750e-07]\n",
            " [ 4.88281250e-06  1.23046875e-05  2.41699219e-05 ...  1.04492187e-05\n",
            "   1.75781250e-06 -3.22265625e-06]\n",
            " [ 1.17187500e-06  1.28417969e-05  2.65625000e-05 ...  7.08007812e-06\n",
            "  -1.07421875e-06 -1.61132812e-06]\n",
            " ...\n",
            " [ 1.12304687e-05  1.82617187e-05  2.89550781e-05 ...  1.04980469e-05\n",
            "  -4.88281250e-07 -2.49023437e-06]\n",
            " [ 8.69140625e-06  1.71386719e-05  2.95898437e-05 ...  1.08886719e-05\n",
            "   7.81250000e-07 -1.80664062e-06]\n",
            " [ 8.74023437e-06  1.49414062e-05  2.55859375e-05 ...  1.04003906e-05\n",
            "  -6.83593750e-07 -4.58984375e-06]]\n",
            "288\n",
            "288\n",
            "\n",
            "\n",
            "******\n",
            "\n",
            "Inizio con:  /content/bci-gpt/BCICIV_2a_gdf/A09E.gdf \n",
            "\n",
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A09E.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "<RawGDF | A09E.gdf, 25 x 675098 (2700.4 s), ~25 KiB, data not loaded>\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
            "[[     0      0      5]\n",
            " [     0      0      3]\n",
            " [ 25808      0      5]\n",
            " ...\n",
            " [671561      0      7]\n",
            " [673120      0      6]\n",
            " [673620      0      7]]\n",
            "{'1023': 1, '1072': 2, '276': 3, '277': 4, '32766': 5, '768': 6, '783': 7}\n",
            "288\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n",
            "\n",
            "\n",
            " (288, 22, 1000)\n",
            "\n",
            "\n",
            " [[-4.88281250e-08  2.39257812e-06  3.41796875e-06 ...  1.31835937e-05\n",
            "   4.78515625e-06 -3.75976562e-06]\n",
            " [ 3.51562500e-06  6.15234375e-06  9.76562500e-06 ...  1.05468750e-05\n",
            "   2.83203125e-06 -3.71093750e-06]\n",
            " [ 3.66210937e-06  6.34765625e-06  8.88671875e-06 ...  1.46484375e-05\n",
            "   5.85937500e-06 -3.75976562e-06]\n",
            " ...\n",
            " [-3.46679687e-06  3.17382812e-06  9.66796875e-06 ...  3.45703125e-05\n",
            "   3.20800781e-05  2.93457031e-05]\n",
            " [-8.49609375e-06 -2.24609375e-06  3.27148437e-06 ...  3.80859375e-05\n",
            "   3.54492187e-05  3.31054687e-05]\n",
            " [-5.32226562e-06  1.75781250e-06  7.17773437e-06 ...  4.17968750e-05\n",
            "   4.25781250e-05  4.25781250e-05]]\n",
            "288\n",
            "288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes Definition"
      ],
      "metadata": {
        "id": "Zgl0oT4fOqDX"
      },
      "id": "Zgl0oT4fOqDX"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ce07daa8",
      "metadata": {
        "id": "ce07daa8"
      },
      "outputs": [],
      "source": [
        "class PatchEmbeddingCNN(nn.Module):\n",
        "    def __init__(self, f1=16, kernel_size=64, D=2, pooling_size1=8, pooling_size2=8, dropout_rate=0.3, number_channel=22, emb_size=40):\n",
        "        super().__init__()\n",
        "        f2 = D*f1\n",
        "        self.cnn_module = nn.Sequential(\n",
        "            # temporal conv kernel size 64=0.25fs\n",
        "            nn.Conv2d(1, f1, (1, kernel_size), (1, 1), padding='same', bias=False), # [batch, 22, 1000]\n",
        "            nn.BatchNorm2d(f1),\n",
        "            # channel depth-wise conv\n",
        "            nn.Conv2d(f1, f2, (number_channel, 1), (1, 1), groups=f1, padding='valid', bias=False), #\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ELU(),\n",
        "            # average pooling 1\n",
        "            nn.AvgPool2d((1, pooling_size1)),  # pooling acts as slicing to obtain 'patch' along the time dimension as in ViT\n",
        "            nn.Dropout(dropout_rate),\n",
        "            # spatial conv\n",
        "            nn.Conv2d(f2, f2, (1, 16), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ELU(),\n",
        "\n",
        "            # average pooling 2 to adjust the length of feature into transformer encoder\n",
        "            nn.AvgPool2d((1, pooling_size2)),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.cnn_module(x)\n",
        "        x = self.projection(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads, dropout):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.keys = nn.Linear(emb_size, emb_size)\n",
        "        self.queries = nn.Linear(emb_size, emb_size)\n",
        "        self.values = nn.Linear(emb_size, emb_size)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
        "        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "\n",
        "        scaling = self.emb_size ** (1 / 2)\n",
        "        att = F.softmax(energy / scaling, dim=-1)\n",
        "        att = self.att_drop(att)\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# PointWise FFN\n",
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size, expansion, drop_p):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, flatten_number, n_classes):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(flatten_number, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn, emb_size, drop_p):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.drop = nn.Dropout(drop_p)\n",
        "        self.layernorm = nn.LayerNorm(emb_size)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        x_input = x\n",
        "        res = self.fn(x, **kwargs)\n",
        "\n",
        "        out = self.layernorm(self.drop(res)+x_input)\n",
        "        return out\n",
        "\n",
        "class TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 num_heads=4,\n",
        "                 drop_p=0.5,\n",
        "                 forward_expansion=4,\n",
        "                 forward_drop_p=0.5):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                MultiHeadAttention(emb_size, num_heads, drop_p),\n",
        "                ), emb_size, drop_p),\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                FeedForwardBlock(emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                ), emb_size, drop_p)\n",
        "\n",
        "            )\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, heads, depth, emb_size):\n",
        "        super().__init__(*[TransformerEncoderBlock(emb_size, heads) for _ in range(depth)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BranchEEGNetTransformer(nn.Sequential):\n",
        "    def __init__(self, heads=4,\n",
        "                 depth=6,\n",
        "                 emb_size=40,\n",
        "                 number_channel=22,\n",
        "                 f1 = 20,\n",
        "                 kernel_size = 64,\n",
        "                 D = 2,\n",
        "                 pooling_size1 = 8,\n",
        "                 pooling_size2 = 8,\n",
        "                 dropout_rate = 0.3,\n",
        "                 **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbeddingCNN(f1=f1,\n",
        "                                 kernel_size=kernel_size,\n",
        "                                 D=D,\n",
        "                                 pooling_size1=pooling_size1,\n",
        "                                 pooling_size2=pooling_size2,\n",
        "                                 dropout_rate=dropout_rate,\n",
        "                                 number_channel=number_channel,\n",
        "                                 emb_size=emb_size),\n",
        "#             TransformerEncoder(heads, depth, emb_size),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PositioinalEncoding(nn.Module):\n",
        "    def __init__(self, embedding, length=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.encoding = nn.Parameter(torch.randn(1, length, embedding))\n",
        "    def forward(self, x): # x-> [batch, embedding, length]\n",
        "        x = x + self.encoding[:, :x.shape[1], :].cuda()\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EEGTransformer(nn.Module):\n",
        "    def __init__(self, heads=4,\n",
        "                 emb_size=40,\n",
        "                 depth=6,\n",
        "                 database_type='A',\n",
        "                 eeg1_f1 = 20,\n",
        "                 eeg1_kernel_size = 64,\n",
        "                 eeg1_D = 2,\n",
        "                 eeg1_pooling_size1 = 8,\n",
        "                 eeg1_pooling_size2 = 8,\n",
        "                 eeg1_dropout_rate = 0.3,\n",
        "                 eeg1_number_channel = 22,\n",
        "                 flatten_eeg1 = 600,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        self.number_class, self.number_channel = numberClassChannel(database_type)\n",
        "        self.emb_size = emb_size\n",
        "        self.flatten_eeg1 = flatten_eeg1\n",
        "        self.flatten = nn.Flatten()\n",
        "        # print('self.number_channel', self.number_channel)\n",
        "        self.cnn = BranchEEGNetTransformer(heads, depth, emb_size, number_channel=self.number_channel,\n",
        "                                              f1 = eeg1_f1,\n",
        "                                              kernel_size = eeg1_kernel_size,\n",
        "                                              D = eeg1_D,\n",
        "                                              pooling_size1 = eeg1_pooling_size1,\n",
        "                                              pooling_size2 = eeg1_pooling_size2,\n",
        "                                              dropout_rate = eeg1_dropout_rate,\n",
        "                                              )\n",
        "        self.position = PositioinalEncoding(emb_size, dropout=0.1)\n",
        "        self.trans = TransformerEncoder(heads, depth, emb_size)\n",
        "#         self.drop = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "        # self.cnn_module = Branchcnn_moduleTransformer(heads, depth, emb_size)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classification = ClassificationHead(self.flatten_eeg1 , self.number_class) # FLATTEN_EEGNet + FLATTEN_cnn_module\n",
        "    def forward(self, x):\n",
        "        cnn = self.cnn(x)\n",
        "\n",
        "        # add label\n",
        "        cnn = cnn * math.sqrt(self.emb_size)\n",
        "        cnn = self.position(cnn)\n",
        "\n",
        "        trans = self.trans(cnn)\n",
        "\n",
        "        features = cnn+trans\n",
        "\n",
        "\n",
        "        out = self.classification(self.flatten(features))\n",
        "        return features, out\n",
        "\n",
        "\n",
        "class ExP():\n",
        "    def __init__(self, nsub, data_dir, result_name,\n",
        "                 epochs=2000,\n",
        "                 number_aug=2,\n",
        "                 number_seg=8,\n",
        "                 gpus=[0],\n",
        "                 evaluate_mode = 'subject-dependent',\n",
        "                 heads=4,\n",
        "                 emb_size=40,\n",
        "                 depth=6,\n",
        "                 dataset_type='A',\n",
        "                 eeg1_f1 = 20,\n",
        "                 eeg1_kernel_size = 64,\n",
        "                 eeg1_D = 2,\n",
        "                 eeg1_pooling_size1 = 8,\n",
        "                 eeg1_pooling_size2 = 8,\n",
        "                 eeg1_dropout_rate = 0.3,\n",
        "                 flatten_eeg1 = 600,\n",
        "                 validate_ratio = 0.2,\n",
        "                 learning_rate = 0.001,\n",
        "                 batch_size = 72,\n",
        "                 ):\n",
        "\n",
        "        super(ExP, self).__init__()\n",
        "        self.dataset_type = dataset_type\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = learning_rate\n",
        "        self.b1 = 0.5\n",
        "        self.b2 = 0.999\n",
        "        self.n_epochs = epochs\n",
        "        self.nSub = nsub\n",
        "        self.number_augmentation = number_aug\n",
        "        self.number_seg = number_seg\n",
        "        self.root = data_dir\n",
        "        self.heads=heads\n",
        "        self.emb_size=emb_size\n",
        "        self.depth=depth\n",
        "        self.result_name = result_name\n",
        "        self.evaluate_mode = evaluate_mode\n",
        "        self.validate_ratio = validate_ratio\n",
        "\n",
        "        self.Tensor = torch.cuda.FloatTensor\n",
        "        self.LongTensor = torch.cuda.LongTensor\n",
        "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "        self.number_class, self.number_channel = numberClassChannel(self.dataset_type)\n",
        "        self.model = EEGTransformer(\n",
        "             heads=self.heads,\n",
        "             emb_size=self.emb_size,\n",
        "             depth=self.depth,\n",
        "            database_type=self.dataset_type,\n",
        "            eeg1_f1=eeg1_f1,\n",
        "            eeg1_D=eeg1_D,\n",
        "            eeg1_kernel_size=eeg1_kernel_size,\n",
        "            eeg1_pooling_size1 = eeg1_pooling_size1,\n",
        "            eeg1_pooling_size2 = eeg1_pooling_size2,\n",
        "            eeg1_dropout_rate = eeg1_dropout_rate,\n",
        "            eeg1_number_channel = self.number_channel,\n",
        "            flatten_eeg1 = flatten_eeg1,\n",
        "            ).cuda()\n",
        "        #self.model = nn.DataParallel(self.model, device_ids=gpus)\n",
        "        self.model = self.model.cuda()\n",
        "        self.model_filename = self.result_name + '/model_{}.pth'.format(self.nSub)\n",
        "\n",
        "    # Segmentation and Reconstruction (S&R) data augmentation\n",
        "    def interaug(self, timg, label):\n",
        "        aug_data = []\n",
        "        aug_label = []\n",
        "        number_records_by_augmentation = self.number_augmentation * int(self.batch_size / self.number_class)\n",
        "        number_segmentation_points = 1000 // self.number_seg\n",
        "        for clsAug in range(self.number_class):\n",
        "            cls_idx = np.where(label == clsAug + 1)\n",
        "            tmp_data = timg[cls_idx]\n",
        "            tmp_label = label[cls_idx]\n",
        "\n",
        "            tmp_aug_data = np.zeros((number_records_by_augmentation, 1, self.number_channel, 1000))\n",
        "            for ri in range(number_records_by_augmentation):\n",
        "                for rj in range(self.number_seg):\n",
        "                    rand_idx = np.random.randint(0, tmp_data.shape[0], self.number_seg)\n",
        "                    tmp_aug_data[ri, :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points] = \\\n",
        "                        tmp_data[rand_idx[rj], :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points]\n",
        "\n",
        "            aug_data.append(tmp_aug_data)\n",
        "            aug_label.append(tmp_label[:number_records_by_augmentation])\n",
        "        aug_data = np.concatenate(aug_data)\n",
        "        aug_label = np.concatenate(aug_label)\n",
        "        aug_shuffle = np.random.permutation(len(aug_data))\n",
        "        aug_data = aug_data[aug_shuffle, :, :]\n",
        "        aug_label = aug_label[aug_shuffle]\n",
        "\n",
        "        aug_data = torch.from_numpy(aug_data).cuda()\n",
        "        aug_data = aug_data.float()\n",
        "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
        "        aug_label = aug_label.long()\n",
        "        return aug_data, aug_label\n",
        "\n",
        "\n",
        "\n",
        "    def get_source_data(self):\n",
        "        (self.train_data,    # (batch, channel, length)\n",
        "         self.train_label,\n",
        "         self.test_data,\n",
        "         self.test_label) = load_data_evaluate(self.root, self.dataset_type, self.nSub, mode_evaluate=self.evaluate_mode)\n",
        "\n",
        "        self.train_data = np.expand_dims(self.train_data, axis=1)  # (288, 1, 22, 1000)\n",
        "        self.train_label = np.transpose(self.train_label)\n",
        "\n",
        "        self.allData = self.train_data\n",
        "        self.allLabel = self.train_label[0]\n",
        "\n",
        "        shuffle_num = np.random.permutation(len(self.allData))\n",
        "        # print(\"len(self.allData):\", len(self.allData))\n",
        "        self.allData = self.allData[shuffle_num, :, :, :]  # (288, 1, 22, 1000)\n",
        "        # print(\"shuffle_num\", shuffle_num)\n",
        "        # print(\"self.allLabel\", self.allLabel)\n",
        "        self.allLabel = self.allLabel[shuffle_num]\n",
        "\n",
        "\n",
        "        print('-'*20, \"train size：\", self.train_data.shape, \"test size：\", self.test_data.shape)\n",
        "        # self.test_data = np.transpose(self.test_data, (2, 1, 0))\n",
        "        self.test_data = np.expand_dims(self.test_data, axis=1)\n",
        "        self.test_label = np.transpose(self.test_label)\n",
        "\n",
        "        self.testData = self.test_data\n",
        "        self.testLabel = self.test_label[0]\n",
        "\n",
        "\n",
        "        # standardize\n",
        "        target_mean = np.mean(self.allData)\n",
        "        target_std = np.std(self.allData)\n",
        "        self.allData = (self.allData - target_mean) / target_std\n",
        "        self.testData = (self.testData - target_mean) / target_std\n",
        "\n",
        "        isSaveDataLabel = False #True\n",
        "        if isSaveDataLabel:\n",
        "            np.save(\"./gradm_data/train_data_{}.npy\".format(self.nSub), self.allData)\n",
        "            np.save(\"./gradm_data/train_lable_{}.npy\".format(self.nSub), self.allLabel)\n",
        "            np.save(\"./gradm_data/test_data_{}.npy\".format(self.nSub), self.testData)\n",
        "            np.save(\"./gradm_data/test_label_{}.npy\".format(self.nSub), self.testLabel)\n",
        "\n",
        "\n",
        "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
        "        return self.allData, self.allLabel, self.testData, self.testLabel\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        img, label, test_data, test_label = self.get_source_data()\n",
        "        # print(\"label size:\", label.shape)\n",
        "        # print(\"label size:\", label)\n",
        "\n",
        "        img = torch.from_numpy(img)\n",
        "        label = torch.from_numpy(label - 1)\n",
        "        dataset = torch.utils.data.TensorDataset(img, label)\n",
        "\n",
        "\n",
        "        test_data = torch.from_numpy(test_data)\n",
        "        test_label = torch.from_numpy(test_label - 1)\n",
        "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        # Optimizers\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
        "\n",
        "        test_data = Variable(test_data.type(self.Tensor))\n",
        "        test_label = Variable(test_label.type(self.LongTensor))\n",
        "        best_epoch = 0\n",
        "        num = 0\n",
        "        min_loss = 100\n",
        "        # recording train_acc, train_loss, test_acc, test_loss\n",
        "        result_process = []\n",
        "        # Train the cnn model\n",
        "        for e in range(self.n_epochs):\n",
        "            self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
        "            epoch_process = {}\n",
        "            epoch_process['epoch'] = e\n",
        "            # in_epoch = time.time()\n",
        "            self.model.train()\n",
        "            outputs_list = []\n",
        "            label_list = []\n",
        "            # 验证集\n",
        "            val_data_list = []\n",
        "            val_label_list = []\n",
        "            for i, (img, label) in enumerate(self.dataloader):\n",
        "                number_sample = img.shape[0]\n",
        "                number_validate = int(self.validate_ratio * number_sample)\n",
        "\n",
        "                # split raw train dataset into real train dataset and validate dataset\n",
        "                train_data = img[:-number_validate]\n",
        "                train_label = label[:-number_validate]\n",
        "\n",
        "                val_data_list.append(img[number_validate:])\n",
        "                val_label_list.append(label[number_validate:])\n",
        "\n",
        "                # real train dataset\n",
        "                img = Variable(train_data.type(self.Tensor))\n",
        "                label = Variable(train_label.type(self.LongTensor))\n",
        "\n",
        "                # data augmentation\n",
        "                #aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
        "                # concat real train dataset and generate aritifical train dataset\n",
        "                #img = torch.cat((img, aug_data))\n",
        "                #label = torch.cat((label, aug_label))\n",
        "\n",
        "                # training model\n",
        "                features, outputs = self.model(img)\n",
        "                outputs_list.append(outputs)\n",
        "                label_list.append(label)\n",
        "                # print(\"train outputs: \", outputs.shape, type(outputs))\n",
        "                # print(features.size())\n",
        "                loss = self.criterion_cls(outputs, label)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            del img\n",
        "            torch.cuda.empty_cache()\n",
        "            # out_epoch = time.time()\n",
        "            # test process\n",
        "            if (e + 1) % 1 == 0:\n",
        "                self.model.eval()\n",
        "                # validate model\n",
        "                val_data = torch.cat(val_data_list).cuda()\n",
        "                val_label = torch.cat(val_label_list).cuda()\n",
        "                val_data = val_data.type(self.Tensor)\n",
        "                val_label = val_label.type(self.LongTensor)\n",
        "\n",
        "                val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
        "                self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "                outputs_list = []\n",
        "                with torch.no_grad():\n",
        "                    for i, (img, _) in enumerate(self.val_dataloader):\n",
        "                        # val model\n",
        "                        img = img.type(self.Tensor).cuda()\n",
        "                        _, Cls = self.model(img)\n",
        "                        outputs_list.append(Cls)\n",
        "                        del img, Cls\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                Cls = torch.cat(outputs_list)\n",
        "\n",
        "                val_loss = self.criterion_cls(Cls, val_label)\n",
        "                val_pred = torch.max(Cls, 1)[1]\n",
        "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
        "\n",
        "                epoch_process['val_acc'] = val_acc\n",
        "                epoch_process['val_loss'] = val_loss.detach().cpu().numpy()\n",
        "\n",
        "                train_pred = torch.max(outputs, 1)[1]\n",
        "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
        "                epoch_process['train_acc'] = train_acc\n",
        "                epoch_process['train_loss'] = loss.detach().cpu().numpy()\n",
        "\n",
        "                num = num + 1\n",
        "\n",
        "                # if min_loss>val_loss:\n",
        "                if min_loss>val_loss:\n",
        "                    min_loss = val_loss\n",
        "                    best_epoch = e\n",
        "                    epoch_process['epoch'] = e\n",
        "                    torch.save(self.model, self.model_filename)\n",
        "                    print(\"{}_{} train_acc: {:.4f} train_loss: {:.6f}\\tval_acc: {:.6f} val_loss: {:.7f}\".format(self.nSub,\n",
        "                                                                                           epoch_process['epoch'],\n",
        "                                                                                           epoch_process['train_acc'],\n",
        "                                                                                           epoch_process['train_loss'],\n",
        "                                                                                           epoch_process['val_acc'],\n",
        "                                                                                           epoch_process['val_loss'],\n",
        "                                                                                        ))\n",
        "\n",
        "\n",
        "            result_process.append(epoch_process)\n",
        "\n",
        "\n",
        "            del label, val_data, val_label\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # load model for test\n",
        "        self.model.eval()\n",
        "        self.model = torch.load(self.model_filename).cuda()\n",
        "        outputs_list = []\n",
        "        with torch.no_grad():\n",
        "            for i, (img, label) in enumerate(self.test_dataloader):\n",
        "                img_test = Variable(img.type(self.Tensor)).cuda()\n",
        "                # label_test = Variable(label.type(self.LongTensor))\n",
        "\n",
        "                # test model\n",
        "                features, outputs = self.model(img_test)\n",
        "                val_pred = torch.max(outputs, 1)[1]\n",
        "                outputs_list.append(outputs)\n",
        "        outputs = torch.cat(outputs_list)\n",
        "        y_pred = torch.max(outputs, 1)[1]\n",
        "\n",
        "\n",
        "        test_acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
        "\n",
        "        print(\"epoch: \", best_epoch, '\\tThe test accuracy is:', test_acc)\n",
        "\n",
        "\n",
        "        df_process = pd.DataFrame(result_process)\n",
        "\n",
        "        return test_acc, test_label, y_pred, df_process, best_epoch\n",
        "        # writer.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation"
      ],
      "metadata": {
        "id": "NTrxYjwaOwJZ"
      },
      "id": "NTrxYjwaOwJZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def main(dirs,\n",
        "         evaluate_mode = 'subject-dependent', # 评估模式：LOSO（跨个体）或其他（subject-dependent, subject-specific），\n",
        "         heads=8,             # heads of MHA\n",
        "         emb_size=48,         # token embding dim\n",
        "         depth=3,             # Transformer encoder depth\n",
        "         dataset_type='A',    # A->'BCI IV2a', B->'BCI IV2b'\n",
        "         eeg1_f1=20,          # features of temporal conv\n",
        "         eeg1_kernel_size=64, # kernel size of temporal conv\n",
        "         eeg1_D=2,            # depth-wise conv\n",
        "         eeg1_pooling_size1=8,# p1\n",
        "         eeg1_pooling_size2=8,# p2\n",
        "         eeg1_dropout_rate=0.3,\n",
        "         flatten_eeg1=600,\n",
        "         validate_ratio = 0.2\n",
        "         ):\n",
        "\n",
        "    if not os.path.exists(dirs):\n",
        "        os.makedirs(dirs)\n",
        "\n",
        "    result_write_metric = ExcelWriter(dirs+\"/result_metric.xlsx\")\n",
        "\n",
        "    result_metric_dict = {}\n",
        "    y_true_pred_dict = { }\n",
        "\n",
        "    process_write = ExcelWriter(dirs+\"/process_train.xlsx\")\n",
        "    pred_true_write = ExcelWriter(dirs+\"/pred_true.xlsx\")\n",
        "    subjects_result = []\n",
        "    best_epochs = []\n",
        "\n",
        "    for i in range(N_SUBJECT):\n",
        "\n",
        "        starttime = datetime.datetime.now()\n",
        "        seed_n = np.random.randint(2024)\n",
        "        print('seed is ' + str(seed_n))\n",
        "        random.seed(seed_n)\n",
        "        np.random.seed(seed_n)\n",
        "        torch.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed_all(seed_n)\n",
        "        index_round =0\n",
        "        print('Subject %d' % (i+1))\n",
        "        exp = ExP(i + 1, DATA_DIR, dirs, EPOCHS, N_AUG, N_SEG, gpus,\n",
        "                  evaluate_mode = evaluate_mode,\n",
        "                  heads=heads,\n",
        "                  emb_size=emb_size,\n",
        "                  depth=depth,\n",
        "                  dataset_type=dataset_type,\n",
        "                  eeg1_f1 = eeg1_f1,\n",
        "                  eeg1_kernel_size = eeg1_kernel_size,\n",
        "                  eeg1_D = eeg1_D,\n",
        "                  eeg1_pooling_size1 = eeg1_pooling_size1,\n",
        "                  eeg1_pooling_size2 = eeg1_pooling_size2,\n",
        "                  eeg1_dropout_rate = eeg1_dropout_rate,\n",
        "                  flatten_eeg1 = flatten_eeg1,\n",
        "                  validate_ratio = validate_ratio\n",
        "                  )\n",
        "\n",
        "        testAcc, Y_true, Y_pred, df_process, best_epoch = exp.train()\n",
        "        true_cpu = Y_true.cpu().numpy().astype(int)\n",
        "        pred_cpu = Y_pred.cpu().numpy().astype(int)\n",
        "        df_pred_true = pd.DataFrame({'pred': pred_cpu, 'true': true_cpu})\n",
        "        df_pred_true.to_excel(pred_true_write, sheet_name=str(i+1))\n",
        "        y_true_pred_dict[i] = df_pred_true\n",
        "\n",
        "        accuracy, precison, recall, f1, kappa = calMetrics(true_cpu, pred_cpu)\n",
        "        subject_result = {'accuray': accuracy*100,\n",
        "                          'precision': precison*100,\n",
        "                          'recall': recall*100,\n",
        "                          'f1': f1*100,\n",
        "                          'kappa': kappa*100\n",
        "                          }\n",
        "        subjects_result.append(subject_result)\n",
        "        df_process.to_excel(process_write, sheet_name=str(i+1))\n",
        "        best_epochs.append(best_epoch)\n",
        "\n",
        "        print(' THE BEST ACCURACY IS ' + str(testAcc) + \"\\tkappa is \" + str(kappa) )\n",
        "\n",
        "\n",
        "        endtime = datetime.datetime.now()\n",
        "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
        "\n",
        "        if i == 0:\n",
        "            yt = Y_true\n",
        "            yp = Y_pred\n",
        "        else:\n",
        "            yt = torch.cat((yt, Y_true))\n",
        "            yp = torch.cat((yp, Y_pred))\n",
        "\n",
        "        df_result = pd.DataFrame(subjects_result)\n",
        "    process_write.close()\n",
        "    pred_true_write.close()\n",
        "\n",
        "\n",
        "    print('**The average Best accuracy is: ' + str(df_result['accuray'].mean()) + \"kappa is: \" + str(df_result['kappa'].mean()) + \"\\n\" )\n",
        "    print(\"best epochs: \", best_epochs)\n",
        "    #df_result.to_excel(result_write_metric, index=False)\n",
        "    result_metric_dict = df_result\n",
        "\n",
        "    mean = df_result.mean(axis=0)\n",
        "    mean.name = 'mean'\n",
        "    std = df_result.std(axis=0)\n",
        "    std.name = 'std'\n",
        "    df_result = pd.concat([df_result, pd.DataFrame(mean).T, pd.DataFrame(std).T])\n",
        "\n",
        "    df_result.to_excel(result_write_metric, index=False)\n",
        "    print('-'*9, ' all result ', '-'*9)\n",
        "    print(df_result)\n",
        "\n",
        "    print(\"*\"*40)\n",
        "\n",
        "    result_write_metric.close()\n",
        "\n",
        "\n",
        "    return result_metric_dict\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #----------------------------------------\n",
        "    DATA_DIR = r'/content/bci-gpt/preprocessed_ds/'\n",
        "    EVALUATE_MODE = 'LOSO-No' # leaving one subject out subject-dependent  subject-indenpedent\n",
        "\n",
        "    N_SUBJECT = 9       # BCI\n",
        "    N_AUG = 3           # data augmentation times for benerating artificial training data set\n",
        "    N_SEG = 8           # segmentation times for S&R\n",
        "\n",
        "    EPOCHS = 1000\n",
        "    EMB_DIM = 16\n",
        "    HEADS = 2\n",
        "    DEPTH = 6\n",
        "    TYPE = 'B'\n",
        "    validate_ratio = 0.3 # split raw train dataset into real train dataset and validate dataset\n",
        "\n",
        "    EEGNet1_F1 = 8\n",
        "    EEGNet1_KERNEL_SIZE=64\n",
        "    EEGNet1_D=2\n",
        "    EEGNet1_POOL_SIZE1 = 8\n",
        "    EEGNet1_POOL_SIZE2 = 8\n",
        "    FLATTEN_EEGNet1 = 240\n",
        "\n",
        "    if EVALUATE_MODE!='LOSO':\n",
        "        EEGNet1_DROPOUT_RATE = 0.5\n",
        "    else:\n",
        "        EEGNet1_DROPOUT_RATE = 0.25\n",
        "\n",
        "\n",
        "    parameters_list = ['A']\n",
        "    for TYPE in parameters_list:\n",
        "        number_class, number_channel = numberClassChannel(TYPE)\n",
        "        RESULT_NAME = \"CTNet_{}_heads_{}_depth_{}_{}\".format(TYPE, HEADS, DEPTH, int(time.time()))\n",
        "\n",
        "        sModel = EEGTransformer(\n",
        "            heads=HEADS,\n",
        "            emb_size=EMB_DIM,\n",
        "            depth=DEPTH,\n",
        "            database_type=TYPE,\n",
        "            eeg1_f1=EEGNet1_F1,\n",
        "            eeg1_D=EEGNet1_D,\n",
        "            eeg1_kernel_size=EEGNet1_KERNEL_SIZE,\n",
        "            eeg1_pooling_size1 = EEGNet1_POOL_SIZE1,\n",
        "            eeg1_pooling_size2 = EEGNet1_POOL_SIZE2,\n",
        "            eeg1_dropout_rate = EEGNet1_DROPOUT_RATE,\n",
        "            eeg1_number_channel = number_channel,\n",
        "            flatten_eeg1 = FLATTEN_EEGNet1,\n",
        "            ).cuda()\n",
        "        summary(sModel, (1, number_channel, 1000))\n",
        "\n",
        "        print(time.asctime(time.localtime(time.time())))\n",
        "\n",
        "        result = main(RESULT_NAME,\n",
        "                        evaluate_mode = EVALUATE_MODE,\n",
        "                        heads=HEADS,\n",
        "                        emb_size=EMB_DIM,\n",
        "                        depth=DEPTH,\n",
        "                        dataset_type=TYPE,\n",
        "                        eeg1_f1 = EEGNet1_F1,\n",
        "                        eeg1_kernel_size = EEGNet1_KERNEL_SIZE,\n",
        "                        eeg1_D = EEGNet1_D,\n",
        "                        eeg1_pooling_size1 = EEGNet1_POOL_SIZE1,\n",
        "                        eeg1_pooling_size2 = EEGNet1_POOL_SIZE2,\n",
        "                        eeg1_dropout_rate = EEGNet1_DROPOUT_RATE,\n",
        "                        flatten_eeg1 = FLATTEN_EEGNet1,\n",
        "                        validate_ratio = validate_ratio,\n",
        "                      )\n",
        "        print(time.asctime(time.localtime(time.time())))"
      ],
      "metadata": {
        "id": "kouZ8Zoin7jp",
        "outputId": "6e823ce5-1cea-4be1-8e57-202f5f629701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "kouZ8Zoin7jp",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 22, 1000]             512\n",
            "       BatchNorm2d-2          [-1, 8, 22, 1000]              16\n",
            "            Conv2d-3          [-1, 16, 1, 1000]             352\n",
            "       BatchNorm2d-4          [-1, 16, 1, 1000]              32\n",
            "               ELU-5          [-1, 16, 1, 1000]               0\n",
            "         AvgPool2d-6           [-1, 16, 1, 125]               0\n",
            "           Dropout-7           [-1, 16, 1, 125]               0\n",
            "            Conv2d-8           [-1, 16, 1, 125]           4,096\n",
            "       BatchNorm2d-9           [-1, 16, 1, 125]              32\n",
            "              ELU-10           [-1, 16, 1, 125]               0\n",
            "        AvgPool2d-11            [-1, 16, 1, 15]               0\n",
            "          Dropout-12            [-1, 16, 1, 15]               0\n",
            "        Rearrange-13               [-1, 15, 16]               0\n",
            "PatchEmbeddingCNN-14               [-1, 15, 16]               0\n",
            "          Dropout-15               [-1, 15, 16]               0\n",
            "PositioinalEncoding-16               [-1, 15, 16]               0\n",
            "           Linear-17               [-1, 15, 16]             272\n",
            "           Linear-18               [-1, 15, 16]             272\n",
            "           Linear-19               [-1, 15, 16]             272\n",
            "          Dropout-20            [-1, 2, 15, 15]               0\n",
            "           Linear-21               [-1, 15, 16]             272\n",
            "MultiHeadAttention-22               [-1, 15, 16]               0\n",
            "          Dropout-23               [-1, 15, 16]               0\n",
            "        LayerNorm-24               [-1, 15, 16]              32\n",
            "      ResidualAdd-25               [-1, 15, 16]               0\n",
            "           Linear-26               [-1, 15, 64]           1,088\n",
            "             GELU-27               [-1, 15, 64]               0\n",
            "          Dropout-28               [-1, 15, 64]               0\n",
            "           Linear-29               [-1, 15, 16]           1,040\n",
            "          Dropout-30               [-1, 15, 16]               0\n",
            "        LayerNorm-31               [-1, 15, 16]              32\n",
            "      ResidualAdd-32               [-1, 15, 16]               0\n",
            "           Linear-33               [-1, 15, 16]             272\n",
            "           Linear-34               [-1, 15, 16]             272\n",
            "           Linear-35               [-1, 15, 16]             272\n",
            "          Dropout-36            [-1, 2, 15, 15]               0\n",
            "           Linear-37               [-1, 15, 16]             272\n",
            "MultiHeadAttention-38               [-1, 15, 16]               0\n",
            "          Dropout-39               [-1, 15, 16]               0\n",
            "        LayerNorm-40               [-1, 15, 16]              32\n",
            "      ResidualAdd-41               [-1, 15, 16]               0\n",
            "           Linear-42               [-1, 15, 64]           1,088\n",
            "             GELU-43               [-1, 15, 64]               0\n",
            "          Dropout-44               [-1, 15, 64]               0\n",
            "           Linear-45               [-1, 15, 16]           1,040\n",
            "          Dropout-46               [-1, 15, 16]               0\n",
            "        LayerNorm-47               [-1, 15, 16]              32\n",
            "      ResidualAdd-48               [-1, 15, 16]               0\n",
            "           Linear-49               [-1, 15, 16]             272\n",
            "           Linear-50               [-1, 15, 16]             272\n",
            "           Linear-51               [-1, 15, 16]             272\n",
            "          Dropout-52            [-1, 2, 15, 15]               0\n",
            "           Linear-53               [-1, 15, 16]             272\n",
            "MultiHeadAttention-54               [-1, 15, 16]               0\n",
            "          Dropout-55               [-1, 15, 16]               0\n",
            "        LayerNorm-56               [-1, 15, 16]              32\n",
            "      ResidualAdd-57               [-1, 15, 16]               0\n",
            "           Linear-58               [-1, 15, 64]           1,088\n",
            "             GELU-59               [-1, 15, 64]               0\n",
            "          Dropout-60               [-1, 15, 64]               0\n",
            "           Linear-61               [-1, 15, 16]           1,040\n",
            "          Dropout-62               [-1, 15, 16]               0\n",
            "        LayerNorm-63               [-1, 15, 16]              32\n",
            "      ResidualAdd-64               [-1, 15, 16]               0\n",
            "           Linear-65               [-1, 15, 16]             272\n",
            "           Linear-66               [-1, 15, 16]             272\n",
            "           Linear-67               [-1, 15, 16]             272\n",
            "          Dropout-68            [-1, 2, 15, 15]               0\n",
            "           Linear-69               [-1, 15, 16]             272\n",
            "MultiHeadAttention-70               [-1, 15, 16]               0\n",
            "          Dropout-71               [-1, 15, 16]               0\n",
            "        LayerNorm-72               [-1, 15, 16]              32\n",
            "      ResidualAdd-73               [-1, 15, 16]               0\n",
            "           Linear-74               [-1, 15, 64]           1,088\n",
            "             GELU-75               [-1, 15, 64]               0\n",
            "          Dropout-76               [-1, 15, 64]               0\n",
            "           Linear-77               [-1, 15, 16]           1,040\n",
            "          Dropout-78               [-1, 15, 16]               0\n",
            "        LayerNorm-79               [-1, 15, 16]              32\n",
            "      ResidualAdd-80               [-1, 15, 16]               0\n",
            "           Linear-81               [-1, 15, 16]             272\n",
            "           Linear-82               [-1, 15, 16]             272\n",
            "           Linear-83               [-1, 15, 16]             272\n",
            "          Dropout-84            [-1, 2, 15, 15]               0\n",
            "           Linear-85               [-1, 15, 16]             272\n",
            "MultiHeadAttention-86               [-1, 15, 16]               0\n",
            "          Dropout-87               [-1, 15, 16]               0\n",
            "        LayerNorm-88               [-1, 15, 16]              32\n",
            "      ResidualAdd-89               [-1, 15, 16]               0\n",
            "           Linear-90               [-1, 15, 64]           1,088\n",
            "             GELU-91               [-1, 15, 64]               0\n",
            "          Dropout-92               [-1, 15, 64]               0\n",
            "           Linear-93               [-1, 15, 16]           1,040\n",
            "          Dropout-94               [-1, 15, 16]               0\n",
            "        LayerNorm-95               [-1, 15, 16]              32\n",
            "      ResidualAdd-96               [-1, 15, 16]               0\n",
            "           Linear-97               [-1, 15, 16]             272\n",
            "           Linear-98               [-1, 15, 16]             272\n",
            "           Linear-99               [-1, 15, 16]             272\n",
            "         Dropout-100            [-1, 2, 15, 15]               0\n",
            "          Linear-101               [-1, 15, 16]             272\n",
            "MultiHeadAttention-102               [-1, 15, 16]               0\n",
            "         Dropout-103               [-1, 15, 16]               0\n",
            "       LayerNorm-104               [-1, 15, 16]              32\n",
            "     ResidualAdd-105               [-1, 15, 16]               0\n",
            "          Linear-106               [-1, 15, 64]           1,088\n",
            "            GELU-107               [-1, 15, 64]               0\n",
            "         Dropout-108               [-1, 15, 64]               0\n",
            "          Linear-109               [-1, 15, 16]           1,040\n",
            "         Dropout-110               [-1, 15, 16]               0\n",
            "       LayerNorm-111               [-1, 15, 16]              32\n",
            "     ResidualAdd-112               [-1, 15, 16]               0\n",
            "         Flatten-113                  [-1, 240]               0\n",
            "         Dropout-114                  [-1, 240]               0\n",
            "          Linear-115                    [-1, 4]             964\n",
            "================================================================\n",
            "Total params: 25,684\n",
            "Trainable params: 25,684\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 3.43\n",
            "Params size (MB): 0.10\n",
            "Estimated Total Size (MB): 3.61\n",
            "----------------------------------------------------------------\n",
            "Thu Feb  6 12:51:30 2025\n",
            "seed is 462\n",
            "Subject 1\n",
            "-------------------- train size： (288, 1, 22, 1000) test size： (288, 22, 1000)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d914d2ec4588>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         result = main(RESULT_NAME,\n\u001b[0m\u001b[1;32m    169\u001b[0m                         \u001b[0mevaluate_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEVALUATE_MODE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                         \u001b[0mheads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-d914d2ec4588>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dirs, evaluate_mode, heads, emb_size, depth, dataset_type, eeg1_f1, eeg1_kernel_size, eeg1_D, eeg1_pooling_size1, eeg1_pooling_size2, eeg1_dropout_rate, flatten_eeg1, validate_ratio)\u001b[0m\n\u001b[1;32m     56\u001b[0m                   )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtestAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mtrue_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mpred_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-78c031378cc6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# print(\"train outputs: \", outputs.shape, type(outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;31m# print(features.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3480\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}