{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/bci-gpt/blob/main/CTNet_2a_82_91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/marco-siino/bci-gpt.git\n",
        "%cd bci-gpt\n"
      ],
      "metadata": {
        "id": "HWnR7fdCnIuC",
        "outputId": "74bc169c-1804-4d5d-a3b3-5304f9eee2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HWnR7fdCnIuC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bci-gpt'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 5), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (21/21), 44.34 KiB | 14.78 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/bci-gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c0af06",
      "metadata": {
        "id": "a3c0af06",
        "outputId": "bc613fd5-c4b5-4459-a199-66a125aa18a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.12.14)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "CTNet: A Convolution-Transformer Network for EEG-Based Motor Imagery Classification\n",
        "\n",
        "author: zhaowei701@163.com\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install mne\n",
        "\n",
        "import os\n",
        "gpus = [0]\n",
        "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "from pandas import ExcelWriter\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "from torch.backends import cudnn\n",
        "from utils import calMetrics\n",
        "from utils import calculatePerClass\n",
        "from utils import numberClassChannel\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from einops import rearrange, reduce, repeat\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from utils import numberClassChannel\n",
        "from utils import load_data_evaluate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "from scipy.io import savemat\n",
        "import scipy.io as sio\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O BCICIV_2a_gdf.zip https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n"
      ],
      "metadata": {
        "id": "ehCLsnvkp0sO",
        "outputId": "80d8c73c-7d6b-4595-98b0-3a13ec5cdb33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ehCLsnvkp0sO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-04 20:29:28--  https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n",
            "Resolving www.bbci.de (www.bbci.de)... 130.149.80.149\n",
            "Connecting to www.bbci.de (www.bbci.de)|130.149.80.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439968864 (420M) [application/zip]\n",
            "Saving to: ‘BCICIV_2a_gdf.zip’\n",
            "\n",
            "BCICIV_2a_gdf.zip   100%[===================>] 419.59M  19.9MB/s    in 23s     \n",
            "\n",
            "2025-02-04 20:29:53 (18.3 MB/s) - ‘BCICIV_2a_gdf.zip’ saved [439968864/439968864]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip BCICIV_2a_gdf.zip -d ./BCICIV_2a_gdf/\n"
      ],
      "metadata": {
        "id": "I7ATagN2qEen",
        "outputId": "5f495aae-4e1b-4002-b996-ccbfe27b7d3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I7ATagN2qEen",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  BCICIV_2a_gdf.zip\n",
            "  inflating: ./BCICIV_2a_gdf/A01E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A01T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A02E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A02T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A03E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A03T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A04E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A04T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A05E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A05T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A06E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A06T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A07E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A07T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A08E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A08T.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A09E.gdf  \n",
            "  inflating: ./BCICIV_2a_gdf/A09T.gdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Function: Read files and preprocess them\n",
        "# Steps:\n",
        "# 1. Import data from the gdf file provided before the competition,\n",
        "#    remove unwanted channels, and select required events.\n",
        "# 2. Select desired time segments for slicing; treat each segment (4s) as one sample.\n",
        "# 3. Import labels from the mat file provided after the competition,\n",
        "#    ensuring they correspond with epochs and their numbers match.\n",
        "# 4. Save the resulting data in a new mat file,\n",
        "#    preparing it for use in the subsequent main.py.\n",
        "\"\"\"\n",
        "\n",
        "def changeGdf2Mat(dir_path, mode=\"train\"):\n",
        "    '''\n",
        "    read data from GDF files and store as mat files\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dir_path : str\n",
        "        GDF file dir path.\n",
        "    mode : str, optional\n",
        "        change train dataset or eval dataset. The default is \"train\".\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    '''\n",
        "    mode_str = ''\n",
        "    if mode==\"train\":\n",
        "        mode_str = 'T'\n",
        "    else:\n",
        "        mode_str = 'E'\n",
        "    for nSub in range(1, 10):\n",
        "        # Load the gdf file\n",
        "        data_filename = dir_path+'BCICIV_2a_gdf/A0{}{}.gdf'.format(nSub, mode_str)\n",
        "        raw = mne.io.read_raw_gdf(data_filename)\n",
        "\n",
        "        # Select the events of interest\n",
        "        events, event_dict = mne.events_from_annotations(raw)\n",
        "        if mode==\"train\":\n",
        "            # train dataset are labeled\n",
        "            event_id = {'Left': event_dict['769'],\n",
        "                        'Right': event_dict['770'],\n",
        "                        'Foot': event_dict['771'],\n",
        "                        'Tongue': event_dict['772']}\n",
        "        else:\n",
        "            # evaluate dataset are labeled as 'Unknnow'\n",
        "            event_id = {'Unknown': event_dict['783']}\n",
        "\n",
        "        # Select the events corresponding to the four categories we are interested in. Here, events[:, 2] refers to the third column of the events array, which represents the event IDs.\n",
        "        selected_events = events[np.isin(events[:, 2], list(event_id.values()))]\n",
        "\n",
        "        # remove EOG channels\n",
        "        raw.info['bads'] += ['EOG-left', 'EOG-central', 'EOG-right']\n",
        "        picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude='bads')\n",
        "        # Epoch the data\n",
        "        # using 4s (1000 sample point ) segmentation\n",
        "        epochs = mne.Epochs(raw, selected_events, event_id, picks=picks,tmin=0, tmax=3.996, preload=True, baseline=None)\n",
        "\n",
        "        filtered_data = epochs.get_data()\n",
        "        label_filename = dir_path + 'true_labels/'+'A0{}{}.mat'.format(nSub, mode_str)\n",
        "        mat = sio.loadmat(label_filename)  # load target mat file\n",
        "        labels = mat['classlabel']\n",
        "\n",
        "        # Save the data and labels to a .mat file\n",
        "        result_filename = 'mymat_raw/A0{}{}.mat'.format(nSub, mode_str)\n",
        "        savemat(result_filename, {'data': filtered_data, 'label': labels})\n",
        "\n",
        "dir_path = './'\n",
        "# prepare train dataset\n",
        "changeGdf2Mat(dir_path, 'train')\n",
        "# prepare test dataset\n",
        "changeGdf2Mat(dir_path, 'eval')"
      ],
      "metadata": {
        "id": "6-3UNFNqo_Co",
        "outputId": "1ad43b45-80cb-48ba-f2ff-ed745d5ee18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "6-3UNFNqo_Co",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/bci-gpt/BCICIV_2a_gdf/A01T.gdf...\n",
            "GDF file detected\n",
            "Setting channel info structure...\n",
            "Could not determine channel type of the following channels, they will be set as EEG:\n",
            "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\n",
            "Creating raw.info structure...\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
            "Not setting metadata\n",
            "288 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 288 events and 1000 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './true_labels/A01T.mat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './true_labels/A01T.mat'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5983bec1973c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# prepare train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mchangeGdf2Mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;31m# prepare test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mchangeGdf2Mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-5983bec1973c>\u001b[0m in \u001b[0;36mchangeGdf2Mat\u001b[0;34m(dir_path, mode)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mfiltered_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlabel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'true_labels/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'A0{}{}.mat'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnSub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_filename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load target mat file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classlabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m    224\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise OSError(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './true_labels/A01T.mat'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce07daa8",
      "metadata": {
        "id": "ce07daa8"
      },
      "outputs": [],
      "source": [
        "class PatchEmbeddingCNN(nn.Module):\n",
        "    def __init__(self, f1=16, kernel_size=64, D=2, pooling_size1=8, pooling_size2=8, dropout_rate=0.3, number_channel=22, emb_size=40):\n",
        "        super().__init__()\n",
        "        f2 = D*f1\n",
        "        self.cnn_module = nn.Sequential(\n",
        "            # temporal conv kernel size 64=0.25fs\n",
        "            nn.Conv2d(1, f1, (1, kernel_size), (1, 1), padding='same', bias=False), # [batch, 22, 1000]\n",
        "            nn.BatchNorm2d(f1),\n",
        "            # channel depth-wise conv\n",
        "            nn.Conv2d(f1, f2, (number_channel, 1), (1, 1), groups=f1, padding='valid', bias=False), #\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ELU(),\n",
        "            # average pooling 1\n",
        "            nn.AvgPool2d((1, pooling_size1)),  # pooling acts as slicing to obtain 'patch' along the time dimension as in ViT\n",
        "            nn.Dropout(dropout_rate),\n",
        "            # spatial conv\n",
        "            nn.Conv2d(f2, f2, (1, 16), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ELU(),\n",
        "\n",
        "            # average pooling 2 to adjust the length of feature into transformer encoder\n",
        "            nn.AvgPool2d((1, pooling_size2)),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.cnn_module(x)\n",
        "        x = self.projection(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads, dropout):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.keys = nn.Linear(emb_size, emb_size)\n",
        "        self.queries = nn.Linear(emb_size, emb_size)\n",
        "        self.values = nn.Linear(emb_size, emb_size)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
        "        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "\n",
        "        scaling = self.emb_size ** (1 / 2)\n",
        "        att = F.softmax(energy / scaling, dim=-1)\n",
        "        att = self.att_drop(att)\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# PointWise FFN\n",
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size, expansion, drop_p):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, flatten_number, n_classes):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(flatten_number, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn, emb_size, drop_p):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.drop = nn.Dropout(drop_p)\n",
        "        self.layernorm = nn.LayerNorm(emb_size)\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        x_input = x\n",
        "        res = self.fn(x, **kwargs)\n",
        "\n",
        "        out = self.layernorm(self.drop(res)+x_input)\n",
        "        return out\n",
        "\n",
        "class TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size,\n",
        "                 num_heads=4,\n",
        "                 drop_p=0.5,\n",
        "                 forward_expansion=4,\n",
        "                 forward_drop_p=0.5):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                MultiHeadAttention(emb_size, num_heads, drop_p),\n",
        "                ), emb_size, drop_p),\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                FeedForwardBlock(emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                ), emb_size, drop_p)\n",
        "\n",
        "            )\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, heads, depth, emb_size):\n",
        "        super().__init__(*[TransformerEncoderBlock(emb_size, heads) for _ in range(depth)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BranchEEGNetTransformer(nn.Sequential):\n",
        "    def __init__(self, heads=4,\n",
        "                 depth=6,\n",
        "                 emb_size=40,\n",
        "                 number_channel=22,\n",
        "                 f1 = 20,\n",
        "                 kernel_size = 64,\n",
        "                 D = 2,\n",
        "                 pooling_size1 = 8,\n",
        "                 pooling_size2 = 8,\n",
        "                 dropout_rate = 0.3,\n",
        "                 **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbeddingCNN(f1=f1,\n",
        "                                 kernel_size=kernel_size,\n",
        "                                 D=D,\n",
        "                                 pooling_size1=pooling_size1,\n",
        "                                 pooling_size2=pooling_size2,\n",
        "                                 dropout_rate=dropout_rate,\n",
        "                                 number_channel=number_channel,\n",
        "                                 emb_size=emb_size),\n",
        "#             TransformerEncoder(heads, depth, emb_size),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PositioinalEncoding(nn.Module):\n",
        "    def __init__(self, embedding, length=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.encoding = nn.Parameter(torch.randn(1, length, embedding))\n",
        "    def forward(self, x): # x-> [batch, embedding, length]\n",
        "        x = x + self.encoding[:, :x.shape[1], :].cuda()\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EEGTransformer(nn.Module):\n",
        "    def __init__(self, heads=4,\n",
        "                 emb_size=40,\n",
        "                 depth=6,\n",
        "                 database_type='A',\n",
        "                 eeg1_f1 = 20,\n",
        "                 eeg1_kernel_size = 64,\n",
        "                 eeg1_D = 2,\n",
        "                 eeg1_pooling_size1 = 8,\n",
        "                 eeg1_pooling_size2 = 8,\n",
        "                 eeg1_dropout_rate = 0.3,\n",
        "                 eeg1_number_channel = 22,\n",
        "                 flatten_eeg1 = 600,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        self.number_class, self.number_channel = numberClassChannel(database_type)\n",
        "        self.emb_size = emb_size\n",
        "        self.flatten_eeg1 = flatten_eeg1\n",
        "        self.flatten = nn.Flatten()\n",
        "        # print('self.number_channel', self.number_channel)\n",
        "        self.cnn = BranchEEGNetTransformer(heads, depth, emb_size, number_channel=self.number_channel,\n",
        "                                              f1 = eeg1_f1,\n",
        "                                              kernel_size = eeg1_kernel_size,\n",
        "                                              D = eeg1_D,\n",
        "                                              pooling_size1 = eeg1_pooling_size1,\n",
        "                                              pooling_size2 = eeg1_pooling_size2,\n",
        "                                              dropout_rate = eeg1_dropout_rate,\n",
        "                                              )\n",
        "        self.position = PositioinalEncoding(emb_size, dropout=0.1)\n",
        "        self.trans = TransformerEncoder(heads, depth, emb_size)\n",
        "#         self.drop = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "        # self.cnn_module = Branchcnn_moduleTransformer(heads, depth, emb_size)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classification = ClassificationHead(self.flatten_eeg1 , self.number_class) # FLATTEN_EEGNet + FLATTEN_cnn_module\n",
        "    def forward(self, x):\n",
        "        cnn = self.cnn(x)\n",
        "\n",
        "        # add label\n",
        "        cnn = cnn * math.sqrt(self.emb_size)\n",
        "        cnn = self.position(cnn)\n",
        "\n",
        "        trans = self.trans(cnn)\n",
        "\n",
        "        features = cnn+trans\n",
        "\n",
        "\n",
        "        out = self.classification(self.flatten(features))\n",
        "        return features, out\n",
        "\n",
        "\n",
        "class ExP():\n",
        "    def __init__(self, nsub, data_dir, result_name,\n",
        "                 epochs=2000,\n",
        "                 number_aug=2,\n",
        "                 number_seg=8,\n",
        "                 gpus=[0],\n",
        "                 evaluate_mode = 'subject-dependent',\n",
        "                 heads=4,\n",
        "                 emb_size=40,\n",
        "                 depth=6,\n",
        "                 dataset_type='A',\n",
        "                 eeg1_f1 = 20,\n",
        "                 eeg1_kernel_size = 64,\n",
        "                 eeg1_D = 2,\n",
        "                 eeg1_pooling_size1 = 8,\n",
        "                 eeg1_pooling_size2 = 8,\n",
        "                 eeg1_dropout_rate = 0.3,\n",
        "                 flatten_eeg1 = 600,\n",
        "                 validate_ratio = 0.2,\n",
        "                 learning_rate = 0.001,\n",
        "                 batch_size = 72,\n",
        "                 ):\n",
        "\n",
        "        super(ExP, self).__init__()\n",
        "        self.dataset_type = dataset_type\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = learning_rate\n",
        "        self.b1 = 0.5\n",
        "        self.b2 = 0.999\n",
        "        self.n_epochs = epochs\n",
        "        self.nSub = nsub\n",
        "        self.number_augmentation = number_aug\n",
        "        self.number_seg = number_seg\n",
        "        self.root = data_dir\n",
        "        self.heads=heads\n",
        "        self.emb_size=emb_size\n",
        "        self.depth=depth\n",
        "        self.result_name = result_name\n",
        "        self.evaluate_mode = evaluate_mode\n",
        "        self.validate_ratio = validate_ratio\n",
        "\n",
        "        self.Tensor = torch.cuda.FloatTensor\n",
        "        self.LongTensor = torch.cuda.LongTensor\n",
        "        self.criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "        self.number_class, self.number_channel = numberClassChannel(self.dataset_type)\n",
        "        self.model = EEGTransformer(\n",
        "             heads=self.heads,\n",
        "             emb_size=self.emb_size,\n",
        "             depth=self.depth,\n",
        "            database_type=self.dataset_type,\n",
        "            eeg1_f1=eeg1_f1,\n",
        "            eeg1_D=eeg1_D,\n",
        "            eeg1_kernel_size=eeg1_kernel_size,\n",
        "            eeg1_pooling_size1 = eeg1_pooling_size1,\n",
        "            eeg1_pooling_size2 = eeg1_pooling_size2,\n",
        "            eeg1_dropout_rate = eeg1_dropout_rate,\n",
        "            eeg1_number_channel = self.number_channel,\n",
        "            flatten_eeg1 = flatten_eeg1,\n",
        "            ).cuda()\n",
        "        #self.model = nn.DataParallel(self.model, device_ids=gpus)\n",
        "        self.model = self.model.cuda()\n",
        "        self.model_filename = self.result_name + '/model_{}.pth'.format(self.nSub)\n",
        "\n",
        "    # Segmentation and Reconstruction (S&R) data augmentation\n",
        "    def interaug(self, timg, label):\n",
        "        aug_data = []\n",
        "        aug_label = []\n",
        "        number_records_by_augmentation = self.number_augmentation * int(self.batch_size / self.number_class)\n",
        "        number_segmentation_points = 1000 // self.number_seg\n",
        "        for clsAug in range(self.number_class):\n",
        "            cls_idx = np.where(label == clsAug + 1)\n",
        "            tmp_data = timg[cls_idx]\n",
        "            tmp_label = label[cls_idx]\n",
        "\n",
        "            tmp_aug_data = np.zeros((number_records_by_augmentation, 1, self.number_channel, 1000))\n",
        "            for ri in range(number_records_by_augmentation):\n",
        "                for rj in range(self.number_seg):\n",
        "                    rand_idx = np.random.randint(0, tmp_data.shape[0], self.number_seg)\n",
        "                    tmp_aug_data[ri, :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points] = \\\n",
        "                        tmp_data[rand_idx[rj], :, :, rj * number_segmentation_points:(rj + 1) * number_segmentation_points]\n",
        "\n",
        "            aug_data.append(tmp_aug_data)\n",
        "            aug_label.append(tmp_label[:number_records_by_augmentation])\n",
        "        aug_data = np.concatenate(aug_data)\n",
        "        aug_label = np.concatenate(aug_label)\n",
        "        aug_shuffle = np.random.permutation(len(aug_data))\n",
        "        aug_data = aug_data[aug_shuffle, :, :]\n",
        "        aug_label = aug_label[aug_shuffle]\n",
        "\n",
        "        aug_data = torch.from_numpy(aug_data).cuda()\n",
        "        aug_data = aug_data.float()\n",
        "        aug_label = torch.from_numpy(aug_label-1).cuda()\n",
        "        aug_label = aug_label.long()\n",
        "        return aug_data, aug_label\n",
        "\n",
        "\n",
        "\n",
        "    def get_source_data(self):\n",
        "        (self.train_data,    # (batch, channel, length)\n",
        "         self.train_label,\n",
        "         self.test_data,\n",
        "         self.test_label) = load_data_evaluate(self.root, self.dataset_type, self.nSub, mode_evaluate=self.evaluate_mode)\n",
        "\n",
        "        self.train_data = np.expand_dims(self.train_data, axis=1)  # (288, 1, 22, 1000)\n",
        "        self.train_label = np.transpose(self.train_label)\n",
        "\n",
        "        self.allData = self.train_data\n",
        "        self.allLabel = self.train_label[0]\n",
        "\n",
        "        shuffle_num = np.random.permutation(len(self.allData))\n",
        "        # print(\"len(self.allData):\", len(self.allData))\n",
        "        self.allData = self.allData[shuffle_num, :, :, :]  # (288, 1, 22, 1000)\n",
        "        # print(\"shuffle_num\", shuffle_num)\n",
        "        # print(\"self.allLabel\", self.allLabel)\n",
        "        self.allLabel = self.allLabel[shuffle_num]\n",
        "\n",
        "\n",
        "        print('-'*20, \"train size：\", self.train_data.shape, \"test size：\", self.test_data.shape)\n",
        "        # self.test_data = np.transpose(self.test_data, (2, 1, 0))\n",
        "        self.test_data = np.expand_dims(self.test_data, axis=1)\n",
        "        self.test_label = np.transpose(self.test_label)\n",
        "\n",
        "        self.testData = self.test_data\n",
        "        self.testLabel = self.test_label[0]\n",
        "\n",
        "\n",
        "        # standardize\n",
        "        target_mean = np.mean(self.allData)\n",
        "        target_std = np.std(self.allData)\n",
        "        self.allData = (self.allData - target_mean) / target_std\n",
        "        self.testData = (self.testData - target_mean) / target_std\n",
        "\n",
        "        isSaveDataLabel = False #True\n",
        "        if isSaveDataLabel:\n",
        "            np.save(\"./gradm_data/train_data_{}.npy\".format(self.nSub), self.allData)\n",
        "            np.save(\"./gradm_data/train_lable_{}.npy\".format(self.nSub), self.allLabel)\n",
        "            np.save(\"./gradm_data/test_data_{}.npy\".format(self.nSub), self.testData)\n",
        "            np.save(\"./gradm_data/test_label_{}.npy\".format(self.nSub), self.testLabel)\n",
        "\n",
        "\n",
        "        # data shape: (trial, conv channel, electrode channel, time samples)\n",
        "        return self.allData, self.allLabel, self.testData, self.testLabel\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        img, label, test_data, test_label = self.get_source_data()\n",
        "        # print(\"label size:\", label.shape)\n",
        "        # print(\"label size:\", label)\n",
        "\n",
        "        img = torch.from_numpy(img)\n",
        "        label = torch.from_numpy(label - 1)\n",
        "        dataset = torch.utils.data.TensorDataset(img, label)\n",
        "\n",
        "\n",
        "        test_data = torch.from_numpy(test_data)\n",
        "        test_label = torch.from_numpy(test_label - 1)\n",
        "        test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        # Optimizers\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n",
        "\n",
        "        test_data = Variable(test_data.type(self.Tensor))\n",
        "        test_label = Variable(test_label.type(self.LongTensor))\n",
        "        best_epoch = 0\n",
        "        num = 0\n",
        "        min_loss = 100\n",
        "        # recording train_acc, train_loss, test_acc, test_loss\n",
        "        result_process = []\n",
        "        # Train the cnn model\n",
        "        for e in range(self.n_epochs):\n",
        "            self.dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)\n",
        "            epoch_process = {}\n",
        "            epoch_process['epoch'] = e\n",
        "            # in_epoch = time.time()\n",
        "            self.model.train()\n",
        "            outputs_list = []\n",
        "            label_list = []\n",
        "            # 验证集\n",
        "            val_data_list = []\n",
        "            val_label_list = []\n",
        "            for i, (img, label) in enumerate(self.dataloader):\n",
        "                number_sample = img.shape[0]\n",
        "                number_validate = int(self.validate_ratio * number_sample)\n",
        "\n",
        "                # split raw train dataset into real train dataset and validate dataset\n",
        "                train_data = img[:-number_validate]\n",
        "                train_label = label[:-number_validate]\n",
        "\n",
        "                val_data_list.append(img[number_validate:])\n",
        "                val_label_list.append(label[number_validate:])\n",
        "\n",
        "                # real train dataset\n",
        "                img = Variable(train_data.type(self.Tensor))\n",
        "                label = Variable(train_label.type(self.LongTensor))\n",
        "\n",
        "                # data augmentation\n",
        "                aug_data, aug_label = self.interaug(self.allData, self.allLabel)\n",
        "                # concat real train dataset and generate aritifical train dataset\n",
        "                img = torch.cat((img, aug_data))\n",
        "                label = torch.cat((label, aug_label))\n",
        "\n",
        "                # training model\n",
        "                features, outputs = self.model(img)\n",
        "                outputs_list.append(outputs)\n",
        "                label_list.append(label)\n",
        "                # print(\"train outputs: \", outputs.shape, type(outputs))\n",
        "                # print(features.size())\n",
        "                loss = self.criterion_cls(outputs, label)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            del img\n",
        "            torch.cuda.empty_cache()\n",
        "            # out_epoch = time.time()\n",
        "            # test process\n",
        "            if (e + 1) % 1 == 0:\n",
        "                self.model.eval()\n",
        "                # validate model\n",
        "                val_data = torch.cat(val_data_list).cuda()\n",
        "                val_label = torch.cat(val_label_list).cuda()\n",
        "                val_data = val_data.type(self.Tensor)\n",
        "                val_label = val_label.type(self.LongTensor)\n",
        "\n",
        "                val_dataset = torch.utils.data.TensorDataset(val_data, val_label)\n",
        "                self.val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "                outputs_list = []\n",
        "                with torch.no_grad():\n",
        "                    for i, (img, _) in enumerate(self.val_dataloader):\n",
        "                        # val model\n",
        "                        img = img.type(self.Tensor).cuda()\n",
        "                        _, Cls = self.model(img)\n",
        "                        outputs_list.append(Cls)\n",
        "                        del img, Cls\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                Cls = torch.cat(outputs_list)\n",
        "\n",
        "                val_loss = self.criterion_cls(Cls, val_label)\n",
        "                val_pred = torch.max(Cls, 1)[1]\n",
        "                val_acc = float((val_pred == val_label).cpu().numpy().astype(int).sum()) / float(val_label.size(0))\n",
        "\n",
        "                epoch_process['val_acc'] = val_acc\n",
        "                epoch_process['val_loss'] = val_loss.detach().cpu().numpy()\n",
        "\n",
        "                train_pred = torch.max(outputs, 1)[1]\n",
        "                train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n",
        "                epoch_process['train_acc'] = train_acc\n",
        "                epoch_process['train_loss'] = loss.detach().cpu().numpy()\n",
        "\n",
        "                num = num + 1\n",
        "\n",
        "                # if min_loss>val_loss:\n",
        "                if min_loss>val_loss:\n",
        "                    min_loss = val_loss\n",
        "                    best_epoch = e\n",
        "                    epoch_process['epoch'] = e\n",
        "                    torch.save(self.model, self.model_filename)\n",
        "                    print(\"{}_{} train_acc: {:.4f} train_loss: {:.6f}\\tval_acc: {:.6f} val_loss: {:.7f}\".format(self.nSub,\n",
        "                                                                                           epoch_process['epoch'],\n",
        "                                                                                           epoch_process['train_acc'],\n",
        "                                                                                           epoch_process['train_loss'],\n",
        "                                                                                           epoch_process['val_acc'],\n",
        "                                                                                           epoch_process['val_loss'],\n",
        "                                                                                        ))\n",
        "\n",
        "\n",
        "            result_process.append(epoch_process)\n",
        "\n",
        "\n",
        "            del label, val_data, val_label\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # load model for test\n",
        "        self.model.eval()\n",
        "        self.model = torch.load(self.model_filename).cuda()\n",
        "        outputs_list = []\n",
        "        with torch.no_grad():\n",
        "            for i, (img, label) in enumerate(self.test_dataloader):\n",
        "                img_test = Variable(img.type(self.Tensor)).cuda()\n",
        "                # label_test = Variable(label.type(self.LongTensor))\n",
        "\n",
        "                # test model\n",
        "                features, outputs = self.model(img_test)\n",
        "                val_pred = torch.max(outputs, 1)[1]\n",
        "                outputs_list.append(outputs)\n",
        "        outputs = torch.cat(outputs_list)\n",
        "        y_pred = torch.max(outputs, 1)[1]\n",
        "\n",
        "\n",
        "        test_acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
        "\n",
        "        print(\"epoch: \", best_epoch, '\\tThe test accuracy is:', test_acc)\n",
        "\n",
        "\n",
        "        df_process = pd.DataFrame(result_process)\n",
        "\n",
        "        return test_acc, test_label, y_pred, df_process, best_epoch\n",
        "        # writer.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(dirs,\n",
        "         evaluate_mode = 'subject-dependent', # 评估模式：LOSO（跨个体）或其他（subject-dependent, subject-specific），\n",
        "         heads=8,             # heads of MHA\n",
        "         emb_size=48,         # token embding dim\n",
        "         depth=3,             # Transformer encoder depth\n",
        "         dataset_type='A',    # A->'BCI IV2a', B->'BCI IV2b'\n",
        "         eeg1_f1=20,          # features of temporal conv\n",
        "         eeg1_kernel_size=64, # kernel size of temporal conv\n",
        "         eeg1_D=2,            # depth-wise conv\n",
        "         eeg1_pooling_size1=8,# p1\n",
        "         eeg1_pooling_size2=8,# p2\n",
        "         eeg1_dropout_rate=0.3,\n",
        "         flatten_eeg1=600,\n",
        "         validate_ratio = 0.2\n",
        "         ):\n",
        "\n",
        "    if not os.path.exists(dirs):\n",
        "        os.makedirs(dirs)\n",
        "\n",
        "    result_write_metric = ExcelWriter(dirs+\"/result_metric.xlsx\")\n",
        "\n",
        "    result_metric_dict = {}\n",
        "    y_true_pred_dict = { }\n",
        "\n",
        "    process_write = ExcelWriter(dirs+\"/process_train.xlsx\")\n",
        "    pred_true_write = ExcelWriter(dirs+\"/pred_true.xlsx\")\n",
        "    subjects_result = []\n",
        "    best_epochs = []\n",
        "\n",
        "    for i in range(N_SUBJECT):\n",
        "\n",
        "        starttime = datetime.datetime.now()\n",
        "        seed_n = np.random.randint(2024)\n",
        "        print('seed is ' + str(seed_n))\n",
        "        random.seed(seed_n)\n",
        "        np.random.seed(seed_n)\n",
        "        torch.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed(seed_n)\n",
        "        torch.cuda.manual_seed_all(seed_n)\n",
        "        index_round =0\n",
        "        print('Subject %d' % (i+1))\n",
        "        exp = ExP(i + 1, DATA_DIR, dirs, EPOCHS, N_AUG, N_SEG, gpus,\n",
        "                  evaluate_mode = evaluate_mode,\n",
        "                  heads=heads,\n",
        "                  emb_size=emb_size,\n",
        "                  depth=depth,\n",
        "                  dataset_type=dataset_type,\n",
        "                  eeg1_f1 = eeg1_f1,\n",
        "                  eeg1_kernel_size = eeg1_kernel_size,\n",
        "                  eeg1_D = eeg1_D,\n",
        "                  eeg1_pooling_size1 = eeg1_pooling_size1,\n",
        "                  eeg1_pooling_size2 = eeg1_pooling_size2,\n",
        "                  eeg1_dropout_rate = eeg1_dropout_rate,\n",
        "                  flatten_eeg1 = flatten_eeg1,\n",
        "                  validate_ratio = validate_ratio\n",
        "                  )\n",
        "\n",
        "        testAcc, Y_true, Y_pred, df_process, best_epoch = exp.train()\n",
        "        true_cpu = Y_true.cpu().numpy().astype(int)\n",
        "        pred_cpu = Y_pred.cpu().numpy().astype(int)\n",
        "        df_pred_true = pd.DataFrame({'pred': pred_cpu, 'true': true_cpu})\n",
        "        df_pred_true.to_excel(pred_true_write, sheet_name=str(i+1))\n",
        "        y_true_pred_dict[i] = df_pred_true\n",
        "\n",
        "        accuracy, precison, recall, f1, kappa = calMetrics(true_cpu, pred_cpu)\n",
        "        subject_result = {'accuray': accuracy*100,\n",
        "                          'precision': precison*100,\n",
        "                          'recall': recall*100,\n",
        "                          'f1': f1*100,\n",
        "                          'kappa': kappa*100\n",
        "                          }\n",
        "        subjects_result.append(subject_result)\n",
        "        df_process.to_excel(process_write, sheet_name=str(i+1))\n",
        "        best_epochs.append(best_epoch)\n",
        "\n",
        "        print(' THE BEST ACCURACY IS ' + str(testAcc) + \"\\tkappa is \" + str(kappa) )\n",
        "\n",
        "\n",
        "        endtime = datetime.datetime.now()\n",
        "        print('subject %d duration: '%(i+1) + str(endtime - starttime))\n",
        "\n",
        "        if i == 0:\n",
        "            yt = Y_true\n",
        "            yp = Y_pred\n",
        "        else:\n",
        "            yt = torch.cat((yt, Y_true))\n",
        "            yp = torch.cat((yp, Y_pred))\n",
        "\n",
        "        df_result = pd.DataFrame(subjects_result)\n",
        "    process_write.close()\n",
        "    pred_true_write.close()\n",
        "\n",
        "\n",
        "    print('**The average Best accuracy is: ' + str(df_result['accuray'].mean()) + \"kappa is: \" + str(df_result['kappa'].mean()) + \"\\n\" )\n",
        "    print(\"best epochs: \", best_epochs)\n",
        "    #df_result.to_excel(result_write_metric, index=False)\n",
        "    result_metric_dict = df_result\n",
        "\n",
        "    mean = df_result.mean(axis=0)\n",
        "    mean.name = 'mean'\n",
        "    std = df_result.std(axis=0)\n",
        "    std.name = 'std'\n",
        "    df_result = pd.concat([df_result, pd.DataFrame(mean).T, pd.DataFrame(std).T])\n",
        "\n",
        "    df_result.to_excel(result_write_metric, index=False)\n",
        "    print('-'*9, ' all result ', '-'*9)\n",
        "    print(df_result)\n",
        "\n",
        "    print(\"*\"*40)\n",
        "\n",
        "    result_write_metric.close()\n",
        "\n",
        "\n",
        "    return result_metric_dict\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #----------------------------------------\n",
        "    DATA_DIR = r'../mymat_raw/'\n",
        "    EVALUATE_MODE = 'LOSO-No' # leaving one subject out subject-dependent  subject-indenpedent\n",
        "\n",
        "    N_SUBJECT = 9       # BCI\n",
        "    N_AUG = 3           # data augmentation times for benerating artificial training data set\n",
        "    N_SEG = 8           # segmentation times for S&R\n",
        "\n",
        "    EPOCHS = 1000\n",
        "    EMB_DIM = 16\n",
        "    HEADS = 2\n",
        "    DEPTH = 6\n",
        "    TYPE = 'B'\n",
        "    validate_ratio = 0.3 # split raw train dataset into real train dataset and validate dataset\n",
        "\n",
        "    EEGNet1_F1 = 8\n",
        "    EEGNet1_KERNEL_SIZE=64\n",
        "    EEGNet1_D=2\n",
        "    EEGNet1_POOL_SIZE1 = 8\n",
        "    EEGNet1_POOL_SIZE2 = 8\n",
        "    FLATTEN_EEGNet1 = 240\n",
        "\n",
        "    if EVALUATE_MODE!='LOSO':\n",
        "        EEGNet1_DROPOUT_RATE = 0.5\n",
        "    else:\n",
        "        EEGNet1_DROPOUT_RATE = 0.25\n",
        "\n",
        "\n",
        "    parameters_list = ['A']\n",
        "    for TYPE in parameters_list:\n",
        "        number_class, number_channel = numberClassChannel(TYPE)\n",
        "        RESULT_NAME = \"CTNet_{}_heads_{}_depth_{}_{}\".format(TYPE, HEADS, DEPTH, int(time.time()))\n",
        "\n",
        "        sModel = EEGTransformer(\n",
        "            heads=HEADS,\n",
        "            emb_size=EMB_DIM,\n",
        "            depth=DEPTH,\n",
        "            database_type=TYPE,\n",
        "            eeg1_f1=EEGNet1_F1,\n",
        "            eeg1_D=EEGNet1_D,\n",
        "            eeg1_kernel_size=EEGNet1_KERNEL_SIZE,\n",
        "            eeg1_pooling_size1 = EEGNet1_POOL_SIZE1,\n",
        "            eeg1_pooling_size2 = EEGNet1_POOL_SIZE2,\n",
        "            eeg1_dropout_rate = EEGNet1_DROPOUT_RATE,\n",
        "            eeg1_number_channel = number_channel,\n",
        "            flatten_eeg1 = FLATTEN_EEGNet1,\n",
        "            ).cuda()\n",
        "        summary(sModel, (1, number_channel, 1000))\n",
        "\n",
        "        print(time.asctime(time.localtime(time.time())))\n",
        "\n",
        "        result = main(RESULT_NAME,\n",
        "                        evaluate_mode = EVALUATE_MODE,\n",
        "                        heads=HEADS,\n",
        "                        emb_size=EMB_DIM,\n",
        "                        depth=DEPTH,\n",
        "                        dataset_type=TYPE,\n",
        "                        eeg1_f1 = EEGNet1_F1,\n",
        "                        eeg1_kernel_size = EEGNet1_KERNEL_SIZE,\n",
        "                        eeg1_D = EEGNet1_D,\n",
        "                        eeg1_pooling_size1 = EEGNet1_POOL_SIZE1,\n",
        "                        eeg1_pooling_size2 = EEGNet1_POOL_SIZE2,\n",
        "                        eeg1_dropout_rate = EEGNet1_DROPOUT_RATE,\n",
        "                        flatten_eeg1 = FLATTEN_EEGNet1,\n",
        "                        validate_ratio = validate_ratio,\n",
        "                      )\n",
        "        print(time.asctime(time.localtime(time.time())))"
      ],
      "metadata": {
        "id": "kouZ8Zoin7jp",
        "outputId": "c594d097-58e4-4f5a-f0b7-8fe85a4b8777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "kouZ8Zoin7jp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 22, 1000]             512\n",
            "       BatchNorm2d-2          [-1, 8, 22, 1000]              16\n",
            "            Conv2d-3          [-1, 16, 1, 1000]             352\n",
            "       BatchNorm2d-4          [-1, 16, 1, 1000]              32\n",
            "               ELU-5          [-1, 16, 1, 1000]               0\n",
            "         AvgPool2d-6           [-1, 16, 1, 125]               0\n",
            "           Dropout-7           [-1, 16, 1, 125]               0\n",
            "            Conv2d-8           [-1, 16, 1, 125]           4,096\n",
            "       BatchNorm2d-9           [-1, 16, 1, 125]              32\n",
            "              ELU-10           [-1, 16, 1, 125]               0\n",
            "        AvgPool2d-11            [-1, 16, 1, 15]               0\n",
            "          Dropout-12            [-1, 16, 1, 15]               0\n",
            "        Rearrange-13               [-1, 15, 16]               0\n",
            "PatchEmbeddingCNN-14               [-1, 15, 16]               0\n",
            "          Dropout-15               [-1, 15, 16]               0\n",
            "PositioinalEncoding-16               [-1, 15, 16]               0\n",
            "           Linear-17               [-1, 15, 16]             272\n",
            "           Linear-18               [-1, 15, 16]             272\n",
            "           Linear-19               [-1, 15, 16]             272\n",
            "          Dropout-20            [-1, 2, 15, 15]               0\n",
            "           Linear-21               [-1, 15, 16]             272\n",
            "MultiHeadAttention-22               [-1, 15, 16]               0\n",
            "          Dropout-23               [-1, 15, 16]               0\n",
            "        LayerNorm-24               [-1, 15, 16]              32\n",
            "      ResidualAdd-25               [-1, 15, 16]               0\n",
            "           Linear-26               [-1, 15, 64]           1,088\n",
            "             GELU-27               [-1, 15, 64]               0\n",
            "          Dropout-28               [-1, 15, 64]               0\n",
            "           Linear-29               [-1, 15, 16]           1,040\n",
            "          Dropout-30               [-1, 15, 16]               0\n",
            "        LayerNorm-31               [-1, 15, 16]              32\n",
            "      ResidualAdd-32               [-1, 15, 16]               0\n",
            "           Linear-33               [-1, 15, 16]             272\n",
            "           Linear-34               [-1, 15, 16]             272\n",
            "           Linear-35               [-1, 15, 16]             272\n",
            "          Dropout-36            [-1, 2, 15, 15]               0\n",
            "           Linear-37               [-1, 15, 16]             272\n",
            "MultiHeadAttention-38               [-1, 15, 16]               0\n",
            "          Dropout-39               [-1, 15, 16]               0\n",
            "        LayerNorm-40               [-1, 15, 16]              32\n",
            "      ResidualAdd-41               [-1, 15, 16]               0\n",
            "           Linear-42               [-1, 15, 64]           1,088\n",
            "             GELU-43               [-1, 15, 64]               0\n",
            "          Dropout-44               [-1, 15, 64]               0\n",
            "           Linear-45               [-1, 15, 16]           1,040\n",
            "          Dropout-46               [-1, 15, 16]               0\n",
            "        LayerNorm-47               [-1, 15, 16]              32\n",
            "      ResidualAdd-48               [-1, 15, 16]               0\n",
            "           Linear-49               [-1, 15, 16]             272\n",
            "           Linear-50               [-1, 15, 16]             272\n",
            "           Linear-51               [-1, 15, 16]             272\n",
            "          Dropout-52            [-1, 2, 15, 15]               0\n",
            "           Linear-53               [-1, 15, 16]             272\n",
            "MultiHeadAttention-54               [-1, 15, 16]               0\n",
            "          Dropout-55               [-1, 15, 16]               0\n",
            "        LayerNorm-56               [-1, 15, 16]              32\n",
            "      ResidualAdd-57               [-1, 15, 16]               0\n",
            "           Linear-58               [-1, 15, 64]           1,088\n",
            "             GELU-59               [-1, 15, 64]               0\n",
            "          Dropout-60               [-1, 15, 64]               0\n",
            "           Linear-61               [-1, 15, 16]           1,040\n",
            "          Dropout-62               [-1, 15, 16]               0\n",
            "        LayerNorm-63               [-1, 15, 16]              32\n",
            "      ResidualAdd-64               [-1, 15, 16]               0\n",
            "           Linear-65               [-1, 15, 16]             272\n",
            "           Linear-66               [-1, 15, 16]             272\n",
            "           Linear-67               [-1, 15, 16]             272\n",
            "          Dropout-68            [-1, 2, 15, 15]               0\n",
            "           Linear-69               [-1, 15, 16]             272\n",
            "MultiHeadAttention-70               [-1, 15, 16]               0\n",
            "          Dropout-71               [-1, 15, 16]               0\n",
            "        LayerNorm-72               [-1, 15, 16]              32\n",
            "      ResidualAdd-73               [-1, 15, 16]               0\n",
            "           Linear-74               [-1, 15, 64]           1,088\n",
            "             GELU-75               [-1, 15, 64]               0\n",
            "          Dropout-76               [-1, 15, 64]               0\n",
            "           Linear-77               [-1, 15, 16]           1,040\n",
            "          Dropout-78               [-1, 15, 16]               0\n",
            "        LayerNorm-79               [-1, 15, 16]              32\n",
            "      ResidualAdd-80               [-1, 15, 16]               0\n",
            "           Linear-81               [-1, 15, 16]             272\n",
            "           Linear-82               [-1, 15, 16]             272\n",
            "           Linear-83               [-1, 15, 16]             272\n",
            "          Dropout-84            [-1, 2, 15, 15]               0\n",
            "           Linear-85               [-1, 15, 16]             272\n",
            "MultiHeadAttention-86               [-1, 15, 16]               0\n",
            "          Dropout-87               [-1, 15, 16]               0\n",
            "        LayerNorm-88               [-1, 15, 16]              32\n",
            "      ResidualAdd-89               [-1, 15, 16]               0\n",
            "           Linear-90               [-1, 15, 64]           1,088\n",
            "             GELU-91               [-1, 15, 64]               0\n",
            "          Dropout-92               [-1, 15, 64]               0\n",
            "           Linear-93               [-1, 15, 16]           1,040\n",
            "          Dropout-94               [-1, 15, 16]               0\n",
            "        LayerNorm-95               [-1, 15, 16]              32\n",
            "      ResidualAdd-96               [-1, 15, 16]               0\n",
            "           Linear-97               [-1, 15, 16]             272\n",
            "           Linear-98               [-1, 15, 16]             272\n",
            "           Linear-99               [-1, 15, 16]             272\n",
            "         Dropout-100            [-1, 2, 15, 15]               0\n",
            "          Linear-101               [-1, 15, 16]             272\n",
            "MultiHeadAttention-102               [-1, 15, 16]               0\n",
            "         Dropout-103               [-1, 15, 16]               0\n",
            "       LayerNorm-104               [-1, 15, 16]              32\n",
            "     ResidualAdd-105               [-1, 15, 16]               0\n",
            "          Linear-106               [-1, 15, 64]           1,088\n",
            "            GELU-107               [-1, 15, 64]               0\n",
            "         Dropout-108               [-1, 15, 64]               0\n",
            "          Linear-109               [-1, 15, 16]           1,040\n",
            "         Dropout-110               [-1, 15, 16]               0\n",
            "       LayerNorm-111               [-1, 15, 16]              32\n",
            "     ResidualAdd-112               [-1, 15, 16]               0\n",
            "         Flatten-113                  [-1, 240]               0\n",
            "         Dropout-114                  [-1, 240]               0\n",
            "          Linear-115                    [-1, 4]             964\n",
            "================================================================\n",
            "Total params: 25,684\n",
            "Trainable params: 25,684\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 3.43\n",
            "Params size (MB): 0.10\n",
            "Estimated Total Size (MB): 3.61\n",
            "----------------------------------------------------------------\n",
            "Tue Feb  4 20:23:25 2025\n",
            "seed is 1923\n",
            "Subject 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../mymat_raw/A01T.mat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../mymat_raw/A01T.mat'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fd5b9efd94af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         result = main(RESULT_NAME,\n\u001b[0m\u001b[1;32m    169\u001b[0m                         \u001b[0mevaluate_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEVALUATE_MODE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                         \u001b[0mheads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-fd5b9efd94af>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dirs, evaluate_mode, heads, emb_size, depth, dataset_type, eeg1_f1, eeg1_kernel_size, eeg1_D, eeg1_pooling_size1, eeg1_pooling_size2, eeg1_dropout_rate, flatten_eeg1, validate_ratio)\u001b[0m\n\u001b[1;32m     56\u001b[0m                   )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtestAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mtrue_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mpred_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5f34f75e2bdb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;31m# print(\"label size:\", label.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# print(\"label size:\", label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5f34f75e2bdb>\u001b[0m in \u001b[0;36mget_source_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m          self.test_label) = load_data_evaluate(self.root, self.dataset_type, self.nSub, mode_evaluate=self.evaluate_mode)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (288, 1, 22, 1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bci-gpt/utils.py\u001b[0m in \u001b[0;36mload_data_evaluate\u001b[0;34m(dir_path, dataset_type, n_sub, mode_evaluate)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_data_LOSO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_data_subject_dependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bci-gpt/utils.py\u001b[0m in \u001b[0;36mload_data_subject_dependent\u001b[0;34m(dir_path, dataset_type, n_sub)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     '''\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bci-gpt/utils.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dir_path, dataset_type, n_sub, mode)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mmode_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'E'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mdata_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'{}{:02d}{}.mat'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (288, 22, 1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdata_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m    224\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise OSError(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../mymat_raw/A01T.mat'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}